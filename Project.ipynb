{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3qMrVJH7proIByCRfr7CN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sophiepavia/RESDIE/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-task Learning with GCN for Graph and Node level predictions about Neighborhood Change"
      ],
      "metadata": {
        "id": "1-ucCBNRYqTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries Used"
      ],
      "metadata": {
        "id": "nJneJSkVZ6MV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "df6Is1F1Y6qY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchvision --quiet\n",
        "# !pip install torch-geometric --quiet"
      ],
      "metadata": {
        "id": "Ll32DAWZZlgA"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data, DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "NL5rVIXfZ5Gr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install datacommons_pandas\n",
        "# !pip install datacommons_pandas --upgrade --quiet\n",
        "# Import Data Commons\n",
        "import datacommons_pandas as dc\n",
        "\n",
        "# Import other required libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "\n",
        "import json\n",
        "import pickle"
      ],
      "metadata": {
        "id": "m55zU5N5NfDW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-task GCN Model"
      ],
      "metadata": {
        "id": "6t7UE89BZxto"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultitaskGCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes_node, num_classes_graph):\n",
        "        super(MultitaskGCN, self).__init__()\n",
        "        # Define the first GCN layer\n",
        "        self.conv1 = GCNConv(num_node_features, 16)\n",
        "        # Define the second GCN layer\n",
        "        self.conv2 = GCNConv(16, 16)\n",
        "\n",
        "        # MLP for node-level prediction\n",
        "        self.mlp_node = torch.nn.Sequential(\n",
        "            torch.nn.Linear(16, 16),\n",
        "            torch.nn.LeakyReLU(),\n",
        "            torch.nn.Linear(16, num_classes_node)\n",
        "        )\n",
        "\n",
        "        # MLP for graph-level prediction\n",
        "        self.mlp_graph = torch.nn.Sequential(\n",
        "            torch.nn.Linear(16, 16),\n",
        "            torch.nn.LeakyReLU(),\n",
        "            torch.nn.Linear(16, num_classes_graph)\n",
        "        )\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "\n",
        "        # Shared feature extraction\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.leaky_relu(x)\n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = F.leaky_relu(x)\n",
        "\n",
        "        # Global mean pooling for graph-level features\n",
        "        x_pool = global_mean_pool(x, batch)\n",
        "\n",
        "        # Node-level prediction\n",
        "        out_node = self.mlp_node(x)\n",
        "\n",
        "        # Graph-level prediction\n",
        "        out_graph = self.mlp_graph(x_pool)\n",
        "\n",
        "        return out_node, out_graph\n",
        "        # return F.log_softmax(out_node, dim=1), F.log_softmax(out_graph, dim=1)"
      ],
      "metadata": {
        "id": "FQ1xF9xRcs4o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "SM3Gw_tibJu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, loader, loss_fn_node, loss_fn_graph):\n",
        "  epochs = 500\n",
        "  for epoch in range(epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_batches = len(loader)\n",
        "\n",
        "    for data in loader:  # Iterate over each batch of data\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      out_node, out_graph = model(data)\n",
        "      # print(f'Max node output: {torch.max(out_node).item()}, Max graph output: {torch.max(out_graph).item()}')\n",
        "\n",
        "      # Node-level loss\n",
        "      loss_node = loss_fn_node(out_node, data.y)\n",
        "\n",
        "      # Graph-level loss\n",
        "      loss_graph = loss_fn_graph(out_graph, data.y_graph)\n",
        "\n",
        "      # Combine losses; you might want to weight these differently\n",
        "      loss = loss_node + loss_graph\n",
        "      loss.backward()\n",
        "      # print(f'Gradient norm (node): {torch.norm(next(model.parameters()).grad)}')\n",
        "      optimizer.step()\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss/total_batches\n",
        "    print(f'Epoch {epoch + 1}, Average Loss: {average_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "iK0EeUnRbLon"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test"
      ],
      "metadata": {
        "id": "uxtHUHIOd1u6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    true_labels_node = []\n",
        "    predictions_node = []\n",
        "    true_labels_graph = []\n",
        "    predictions_graph = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in loader:  # Process each batch\n",
        "            out_node, out_graph = model(data)\n",
        "            _, pred_node = out_node.max(dim=1)\n",
        "            _, pred_graph = out_graph.max(dim=1)\n",
        "\n",
        "            # Append predictions and labels for later evaluation\n",
        "            true_labels_node.extend(data.y.tolist())\n",
        "            predictions_node.extend(pred_node.tolist())\n",
        "            true_labels_graph.extend(data.y_graph.tolist())\n",
        "            predictions_graph.extend(pred_graph.tolist())\n",
        "\n",
        "    # Calculate metrics for node-level predictions\n",
        "    node_precision = precision_score(true_labels_node, predictions_node, average='macro')\n",
        "    node_recall = recall_score(true_labels_node, predictions_node, average='macro')\n",
        "    node_f1 = f1_score(true_labels_node, predictions_node, average='macro')\n",
        "\n",
        "    # Calculate metrics for graph-level predictions\n",
        "    graph_precision = precision_score(true_labels_graph, predictions_graph, average='macro')\n",
        "    graph_recall = recall_score(true_labels_graph, predictions_graph, average='macro')\n",
        "    graph_f1 = f1_score(true_labels_graph, predictions_graph, average='macro')\n",
        "\n",
        "    # Accuracy calculations\n",
        "    node_acc = sum(1 for true, pred in zip(true_labels_node, predictions_node) if true == pred) / len(true_labels_node)\n",
        "    graph_acc = sum(1 for true, pred in zip(true_labels_graph, predictions_graph) if true == pred) / len(true_labels_graph)\n",
        "\n",
        "    return {\n",
        "        'Node Accuracy': node_acc,\n",
        "        'Node Precision': node_precision,\n",
        "        'Node Recall': node_recall,\n",
        "        'Node F1-Score': node_f1,\n",
        "        'Graph Accuracy': graph_acc,\n",
        "        'Graph Precision': graph_precision,\n",
        "        'Graph Recall': graph_recall,\n",
        "        'Graph F1-Score': graph_f1\n",
        "    }\n"
      ],
      "metadata": {
        "id": "982EIFk9J2we"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def evaluate(model, loader):\n",
        "#   model.eval()\n",
        "#   total_correct_node = 0\n",
        "#   total_nodes = 0\n",
        "#   total_correct_graph = 0\n",
        "#   total_graphs = 0\n",
        "\n",
        "#   with torch.no_grad():\n",
        "#     for data in loader:  # Process each batch\n",
        "#       out_node, out_graph = model(data)\n",
        "#       _, pred_node = out_node.max(dim=1)\n",
        "#       correct_node = pred_node.eq(data.y).sum().item()\n",
        "#       total_correct_node += correct_node\n",
        "#       total_nodes += data.y.size(0)\n",
        "\n",
        "#       _, pred_graph = out_graph.max(dim=1)\n",
        "#       correct_graph = pred_graph.eq(data.y_graph).sum().item()\n",
        "#       total_correct_graph += correct_graph\n",
        "#       total_graphs += data.y_graph.size(0)\n",
        "\n",
        "#   node_acc = total_correct_node / total_nodes\n",
        "#   graph_acc = total_correct_graph / total_graphs\n",
        "\n",
        "#   return node_acc, graph_acc"
      ],
      "metadata": {
        "id": "lLjc4fEHd2zL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Set up: Census Data Exctraction"
      ],
      "metadata": {
        "id": "OrYvU-Jv5Z5N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process data for a specific year\n",
        "def process_data_for_year(year, data_dict):\n",
        "    result = []\n",
        "    for geo_id, metrics in data_dict.items():\n",
        "        row = {'GeoID': geo_id}\n",
        "        if metrics['Median_Income_Household'] and metrics['Median_HomeValue_HousingUnit_OccupiedHousingUnit_OwnerOccupied'] and metrics['Count_Person_EducationalAttainmentBachelorsDegreeOrHigher'] and metrics['Count_Person_WhiteAlone']:\n",
        "          income_data = metrics['Median_Income_Household']['sourceSeries'][0]['val']\n",
        "          if year in income_data:\n",
        "              row[f'{year}_Median_Income'] = income_data[year]\n",
        "\n",
        "          home_value_data = metrics['Median_HomeValue_HousingUnit_OccupiedHousingUnit_OwnerOccupied']['sourceSeries'][0]['val']\n",
        "          if year in home_value_data:\n",
        "              row[f'{year}_Median_Home_Value'] = home_value_data[year]\n",
        "\n",
        "          education_data = metrics['Count_Person_EducationalAttainmentBachelorsDegreeOrHigher']['sourceSeries'][0]['val']\n",
        "          if year in education_data:\n",
        "              row[f'{year}_Bachelor_Degree'] = education_data[year]\n",
        "\n",
        "          person_data = metrics['Count_Person']['sourceSeries'][0]['val']\n",
        "          if year in person_data:\n",
        "              row[f'{year}_Persons'] = person_data[year]\n",
        "\n",
        "          race_data = metrics['Count_Person_WhiteAlone']['sourceSeries'][0]['val']\n",
        "          if year in race_data:\n",
        "              row[f'{year}_Count_White'] = race_data[year]\n",
        "\n",
        "          result.append(row)\n",
        "    return pd.DataFrame(result)"
      ],
      "metadata": {
        "id": "R3O1Kwv8dprv"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features_census_tracts(df_2012,df_2019,income_percentile_40=None,home_value_percentile_40=None,education_threshold=None,home_threshold=None):\n",
        "  df_2012[\"2012_Percentage_College\"] = df_2012['2012_Bachelor_Degree']/df_2012['2012_Persons'] * 100\n",
        "  df_2012[\"2012_Percentage_Non_White\"] = (df_2012['2012_Persons'] - df_2012['2012_Count_White'])/df_2012['2012_Persons'] * 100\n",
        "\n",
        "  df_2019[\"2019_Percentage_College\"] = df_2019['2019_Bachelor_Degree']/df_2019['2019_Persons'] * 100\n",
        "  df_2019[\"2019_Percentage_Non_White\"] = (df_2019['2019_Persons'] - df_2019['2019_Count_White'])/df_2019['2019_Persons'] * 100\n",
        "\n",
        "  df_final = pd.DataFrame()\n",
        "  df_new = df_2012.merge(df_2019, on='GeoID')\n",
        "  # df_new = df_new.dropna()\n",
        "\n",
        "  df_final['GeoID'] = df_new['GeoID']\n",
        "  df_final[\"Percent_Change_Income\"] = (df_new['2019_Median_Income']-df_new['2012_Median_Income'])/df_new['2012_Median_Income'] * 100\n",
        "  df_final[\"Percent_Change_Home\"] = (df_new['2019_Median_Home_Value']-df_new['2012_Median_Home_Value'])/df_new['2012_Median_Home_Value'] * 100\n",
        "  df_final[\"Percent_Change_Education\"] = (df_new['2019_Percentage_College']-df_new['2012_Percentage_College'])/df_new['2012_Percentage_College'] * 100\n",
        "  df_final[\"Percent_Change_Race\"] = (df_new['2019_Percentage_Non_White']-df_new['2012_Percentage_Non_White'])/df_new['2012_Percentage_Non_White'] * 100\n",
        "\n",
        "  if income_percentile_40 is None and home_value_percentile_40 is None:\n",
        "    income_percentile_40 = df_new['2012_Median_Income'].quantile(0.4)\n",
        "    home_value_percentile_40 = df_new['2012_Median_Home_Value'].quantile(0.4)\n",
        "\n",
        "  df_final['eligible'] = ((df_new['2012_Median_Income'] <= income_percentile_40) & (df_new['2012_Median_Home_Value'] <= home_value_percentile_40)).astype(int)\n",
        "\n",
        "  if education_threshold is None and home_threshold is None:\n",
        "    education_threshold = df_final['Percent_Change_Education'].quantile(2/3)\n",
        "    home_threshold = df_final['Percent_Change_Home'].quantile(2/3)\n",
        "\n",
        "  df_final['label'] = ((df_final['Percent_Change_Education'] > education_threshold) & (df_final['Percent_Change_Home'] > home_threshold) & df_final['eligible'] == 1).astype(int)\n",
        "  return df_final, income_percentile_40, home_value_percentile_40, education_threshold, home_threshold"
      ],
      "metadata": {
        "id": "mun6jZ5pdrsd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Census tract extraction"
      ],
      "metadata": {
        "id": "7rU3dOYFdsbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Davidson County\n",
        "county = 'geoId/47037'"
      ],
      "metadata": {
        "id": "0tLVyTbF5ggr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get lists of census tracts within the County, respectively.\n",
        "census_tracts = dc.get_places_in([county], 'CensusTract')[county]"
      ],
      "metadata": {
        "id": "y51fxe6M5phV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats = dc.get_stat_all(census_tracts, [\"Median_Income_Household\",\"Median_HomeValue_HousingUnit_OccupiedHousingUnit_OwnerOccupied\", \"Count_Person_EducationalAttainmentBachelorsDegreeOrHigher\", 'Count_Person_WhiteAlone',\"Count_Person\"])"
      ],
      "metadata": {
        "id": "5R3W14TqKy8P"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "geo_ids = list(stats.keys())\n",
        "len(geo_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjYlZbNyUxD7",
        "outputId": "1c1fbb02-a8d1-4c39-aad3-1b48486779d6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames for each year\n",
        "df_2012 = process_data_for_year('2012', stats)\n",
        "df_2019 = process_data_for_year('2019', stats)\n",
        "\n",
        "# Get Features\n",
        "df_census_tracts, ip4,hp4,ep,hp = get_features_census_tracts(df_2012,df_2019)\n",
        "df_census_tracts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "teZZ_yQMzcHC",
        "outputId": "3c1caf49-2f25-47aa-9d9d-c8344e28cfaf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 GeoID  Percent_Change_Income  Percent_Change_Home  \\\n",
              "0    geoId/47037010702              10.403512            40.737564   \n",
              "1    geoId/47037011700             115.567794           124.535554   \n",
              "2    geoId/47037013201              18.137818            59.118644   \n",
              "3    geoId/47037019003              46.901352            10.564784   \n",
              "4    geoId/47037019114              15.193223            27.232143   \n",
              "..                 ...                    ...                  ...   \n",
              "152  geoId/47037011200              33.476369            78.235673   \n",
              "153  geoId/47037015623               1.088139            20.379747   \n",
              "154  geoId/47037017701              49.464953            84.306060   \n",
              "155  geoId/47037018404              46.612046            16.240071   \n",
              "156  geoId/47037018410              25.465946            31.477357   \n",
              "\n",
              "     Percent_Change_Education  Percent_Change_Race  eligible  label  \n",
              "0                   40.081976            19.679303         1      0  \n",
              "1                  114.648886           -11.483863         0      0  \n",
              "2                   12.325231           -28.251171         0      0  \n",
              "3                   97.523760           -11.089869         0      0  \n",
              "4                   -5.772429            11.899245         0      0  \n",
              "..                        ...                  ...       ...    ...  \n",
              "152                 45.993140           -22.123051         0      0  \n",
              "153                 11.109573           -39.465802         0      0  \n",
              "154                  4.012711            11.881930         0      0  \n",
              "155                  2.303056           211.543622         0      0  \n",
              "156                  4.786674            43.130070         0      0  \n",
              "\n",
              "[157 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71f365c3-1b7a-46d2-a549-bebce8ade745\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>GeoID</th>\n",
              "      <th>Percent_Change_Income</th>\n",
              "      <th>Percent_Change_Home</th>\n",
              "      <th>Percent_Change_Education</th>\n",
              "      <th>Percent_Change_Race</th>\n",
              "      <th>eligible</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>geoId/47037010702</td>\n",
              "      <td>10.403512</td>\n",
              "      <td>40.737564</td>\n",
              "      <td>40.081976</td>\n",
              "      <td>19.679303</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>geoId/47037011700</td>\n",
              "      <td>115.567794</td>\n",
              "      <td>124.535554</td>\n",
              "      <td>114.648886</td>\n",
              "      <td>-11.483863</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>geoId/47037013201</td>\n",
              "      <td>18.137818</td>\n",
              "      <td>59.118644</td>\n",
              "      <td>12.325231</td>\n",
              "      <td>-28.251171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geoId/47037019003</td>\n",
              "      <td>46.901352</td>\n",
              "      <td>10.564784</td>\n",
              "      <td>97.523760</td>\n",
              "      <td>-11.089869</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>geoId/47037019114</td>\n",
              "      <td>15.193223</td>\n",
              "      <td>27.232143</td>\n",
              "      <td>-5.772429</td>\n",
              "      <td>11.899245</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>geoId/47037011200</td>\n",
              "      <td>33.476369</td>\n",
              "      <td>78.235673</td>\n",
              "      <td>45.993140</td>\n",
              "      <td>-22.123051</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>geoId/47037015623</td>\n",
              "      <td>1.088139</td>\n",
              "      <td>20.379747</td>\n",
              "      <td>11.109573</td>\n",
              "      <td>-39.465802</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>geoId/47037017701</td>\n",
              "      <td>49.464953</td>\n",
              "      <td>84.306060</td>\n",
              "      <td>4.012711</td>\n",
              "      <td>11.881930</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>geoId/47037018404</td>\n",
              "      <td>46.612046</td>\n",
              "      <td>16.240071</td>\n",
              "      <td>2.303056</td>\n",
              "      <td>211.543622</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>geoId/47037018410</td>\n",
              "      <td>25.465946</td>\n",
              "      <td>31.477357</td>\n",
              "      <td>4.786674</td>\n",
              "      <td>43.130070</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71f365c3-1b7a-46d2-a549-bebce8ade745')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71f365c3-1b7a-46d2-a549-bebce8ade745 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71f365c3-1b7a-46d2-a549-bebce8ade745');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17668443-4829-46b9-92a9-82203408b3bc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17668443-4829-46b9-92a9-82203408b3bc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17668443-4829-46b9-92a9-82203408b3bc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_440eb8e6-a8fd-4a5b-91a3-f472a8842b75\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_census_tracts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_440eb8e6-a8fd-4a5b-91a3-f472a8842b75 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_census_tracts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_census_tracts",
              "summary": "{\n  \"name\": \"df_census_tracts\",\n  \"rows\": 157,\n  \"fields\": [\n    {\n      \"column\": \"GeoID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 157,\n        \"samples\": [\n          \"geoId/47037014300\",\n          \"geoId/47037015803\",\n          \"geoId/47037016200\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_Change_Income\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.54888647298119,\n        \"min\": -24.992822737567387,\n        \"max\": 241.4087109916418,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          11.121992477019297,\n          18.694979323642084,\n          3.1365163887851684\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_Change_Home\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 38.68660402511173,\n        \"min\": 5.555555555555555,\n        \"max\": 212.32458816351433,\n        \"num_unique_values\": 156,\n        \"samples\": [\n          12.302284710017574,\n          20.70744288872513,\n          26.87028140013727\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_Change_Education\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 60.04532628245031,\n        \"min\": -38.47355750067761,\n        \"max\": 271.14493610675436,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          57.81637717121589,\n          16.514908092195018,\n          35.46393737727973\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Percent_Change_Race\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50.20502303965627,\n        \"min\": -82.01321773370726,\n        \"max\": 313.0650277557494,\n        \"num_unique_values\": 157,\n        \"samples\": [\n          -13.598181424550765,\n          -5.893115073671451,\n          -12.947150310234365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eligible\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Census block group extraction"
      ],
      "metadata": {
        "id": "KyDkt8N7dybk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "block_groups = {}\n",
        "for ct in census_tracts:\n",
        "  blocks = dc.get_places_in([ct], 'CensusBlockGroup')[ct]\n",
        "  stats = dc.get_stat_all(blocks, [\"Median_Income_Household\",\"Median_HomeValue_HousingUnit_OccupiedHousingUnit_OwnerOccupied\", \"Count_Person_EducationalAttainmentBachelorsDegreeOrHigher\", 'Count_Person_WhiteAlone',\"Count_Person\"])\n",
        "  df_2012 = process_data_for_year('2012', stats)\n",
        "  df_2019 = process_data_for_year('2019', stats)\n",
        "  try:\n",
        "    df_final, _,_,_,_ = get_features_census_tracts(df_2012,df_2019,ip4,hp4,ep,hp)\n",
        "    block_groups[ct] = df_final\n",
        "  except:\n",
        "    print(\"block group data empty for ct: \", ct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T02eSXLKz0WK",
        "outputId": "af223aed-d940-49fa-d3ae-11028d974eab"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "block group data empty for ct:  geoId/47037013000\n",
            "block group data empty for ct:  geoId/47037013602\n",
            "block group data empty for ct:  geoId/47037014400\n",
            "block group data empty for ct:  geoId/47037014800\n",
            "block group data empty for ct:  geoId/47037016500\n",
            "block group data empty for ct:  geoId/47037980100\n",
            "block group data empty for ct:  geoId/47037980200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('block_groups2.pkl', 'wb') as file:\n",
        "#     pickle.dump(block_groups, file)"
      ],
      "metadata": {
        "id": "PTPZ4bQaqGZ3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data prep for Training and Testing"
      ],
      "metadata": {
        "id": "4EAGBDL_Yex0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in edge attributes\n",
        "with open('/edge_attr.pkl', 'rb') as file:\n",
        "  edge_attr = pickle.load(file)\n",
        "\n",
        "data_list = []\n",
        "graph_labels_list = []\n",
        "\n",
        "for id in block_groups.keys():\n",
        "  features = block_groups[id][['Percent_Change_Income', 'Percent_Change_Home', 'Percent_Change_Education', 'Percent_Change_Race']].to_numpy()\n",
        "\n",
        "  node_features = torch.tensor(features, dtype=torch.float)\n",
        "  neighbors = edge_attr[id]\n",
        "\n",
        "  if neighbors and max(max(neighbors)) < len(features):\n",
        "    edge_index = torch.tensor(neighbors, dtype=torch.long).t().contiguous()\n",
        "\n",
        "    # Node-level labels and a graph-level label\n",
        "    node_labels = torch.tensor(block_groups[id]['label'].values)  # binary labels for node-level task\n",
        "    graph_label = torch.tensor([df_census_tracts[df_census_tracts['GeoID'] == id]['label'].iloc[0]], dtype=torch.long)\n",
        "\n",
        "    # PyTorch Geometric Data object\n",
        "    data = Data(x=node_features, edge_index=edge_index, y=node_labels)\n",
        "    data.y_graph = graph_label  # Add graph-level label as an additional attribute\n",
        "    data_list.append(data)\n",
        "\n",
        "cleaned_data_list = []\n",
        "for data in data_list:\n",
        "  if torch.isnan(data.x).any() or torch.isnan(data.y).any() or torch.isinf(data.x).any() or torch.isinf(data.y).any():\n",
        "    continue  # Skip this Data object\n",
        "  cleaned_data_list.append(data)\n",
        "\n",
        "# Data object has a y_graph attribute that represents the graph-level label\n",
        "graph_labels = [data.y_graph.item() for data in cleaned_data_list]"
      ],
      "metadata": {
        "id": "SxjYL___ZAi1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqh6RiL4yYhR",
        "outputId": "3258b1f3-7c7e-473f-d672-1fd1078a15c4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "131"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_data_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5_HOhHNnw7m",
        "outputId": "84ecdc51-970d-459c-99c5-b72f1b239a25"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Test Split"
      ],
      "metadata": {
        "id": "GZakt4XJN4Za"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train_data, test_data = train_test_split(cleaned_data_list, test_size=0.1, stratify=graph_labels)\n",
        "\n",
        "# Create a DataLoader to batch Data objects\n",
        "# train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "# test_loader = DataLoader(test_data,batch_size=16,shuffle=False)"
      ],
      "metadata": {
        "id": "ZeVrwVjcN3xx"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Model"
      ],
      "metadata": {
        "id": "vaVSIm_cN8Uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultitaskGCN(num_node_features=4, num_classes_node=2, num_classes_graph=2)"
      ],
      "metadata": {
        "id": "oFWg7QSWwq9T"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set Optimizers"
      ],
      "metadata": {
        "id": "4Kig7-IxN-Yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn_node = torch.nn.CrossEntropyLoss()  # For node-level classification\n",
        "loss_fn_graph = torch.nn.CrossEntropyLoss()  # For graph-level classification"
      ],
      "metadata": {
        "id": "oKxM8khXwvXM"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "0uhC_HaSOB9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train(model, optimizer, train_loader, loss_fn_node, loss_fn_graph)"
      ],
      "metadata": {
        "id": "wGDrAQxsMnqD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaulate"
      ],
      "metadata": {
        "id": "Z2uLt1reOD2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# node_acc, graph_acc = evaluate(model, test_loader)\n",
        "# print(f'Node-level Accuracy: {node_acc:.4f}, Graph-level Accuracy: {graph_acc:.4f}')"
      ],
      "metadata": {
        "id": "cxc83Mp6LylF"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### K-fold cross validation"
      ],
      "metadata": {
        "id": "QR2GmVHGsyGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5\n",
        "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "results = []\n",
        "# Perform k-fold cross-validation\n",
        "for fold, (train_idx, test_idx) in enumerate(kf.split(cleaned_data_list)):\n",
        "    train_data = [cleaned_data_list[i] for i in train_idx]\n",
        "    test_data = [cleaned_data_list[i] for i in test_idx]\n",
        "\n",
        "    train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
        "    for data in train_loader:\n",
        "      assert not torch.isinf(data.x).any(), \"NaNs in input features\"\n",
        "      assert not torch.isinf(data.y).any(), \"NaNs in node labels\"\n",
        "      assert not torch.isinf(data.y_graph).any(), \"NaNs in graph labels\"\n",
        "\n",
        "    test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
        "\n",
        "    # Training phase\n",
        "    train(model, optimizer, train_loader, loss_fn_node, loss_fn_graph)\n",
        "\n",
        "    # Evaluation phase\n",
        "    result = evaluate(model,test_loader)\n",
        "    results.append((result['Node Accuracy'], result['Graph Accuracy']))\n",
        "    print(f\"Fold {fold + 1}/{num_folds}\")\n",
        "    # print(f\"Training Loss: {train_loss:.4f}\")\n",
        "    print(f\"Node-level Accuracy: {result['Node Accuracy']:.4f}, Graph-level Accuracy: {result['Graph Accuracy']:.4f}\")\n",
        "\n",
        "# Aggregate and display final results\n",
        "average_node_accuracy = sum([res[0] for res in results]) / num_folds\n",
        "average_graph_accuracy = sum([res[1] for res in results]) / num_folds\n",
        "print(f\"Average Node-level Accuracy: {average_node_accuracy:.4f}\")\n",
        "print(f\"Average Graph-level Accuracy: {average_graph_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JatqaS6Asz02",
        "outputId": "cfb7d312-8001-4b0d-8cd7-1e49760b4c11"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Average Loss: 0.0176\n",
            "Epoch 2, Average Loss: 0.0196\n",
            "Epoch 3, Average Loss: 0.0193\n",
            "Epoch 4, Average Loss: 0.0192\n",
            "Epoch 5, Average Loss: 0.0189\n",
            "Epoch 6, Average Loss: 0.0157\n",
            "Epoch 7, Average Loss: 0.0190\n",
            "Epoch 8, Average Loss: 0.0166\n",
            "Epoch 9, Average Loss: 0.0202\n",
            "Epoch 10, Average Loss: 0.0156\n",
            "Epoch 11, Average Loss: 0.0199\n",
            "Epoch 12, Average Loss: 0.0244\n",
            "Epoch 13, Average Loss: 0.0164\n",
            "Epoch 14, Average Loss: 0.0183\n",
            "Epoch 15, Average Loss: 0.0196\n",
            "Epoch 16, Average Loss: 0.0198\n",
            "Epoch 17, Average Loss: 0.0199\n",
            "Epoch 18, Average Loss: 0.0250\n",
            "Epoch 19, Average Loss: 0.0146\n",
            "Epoch 20, Average Loss: 0.0197\n",
            "Epoch 21, Average Loss: 0.0169\n",
            "Epoch 22, Average Loss: 0.0173\n",
            "Epoch 23, Average Loss: 0.0173\n",
            "Epoch 24, Average Loss: 0.0170\n",
            "Epoch 25, Average Loss: 0.0256\n",
            "Epoch 26, Average Loss: 0.0173\n",
            "Epoch 27, Average Loss: 0.0324\n",
            "Epoch 28, Average Loss: 0.0179\n",
            "Epoch 29, Average Loss: 0.0296\n",
            "Epoch 30, Average Loss: 0.0244\n",
            "Epoch 31, Average Loss: 5.3769\n",
            "Epoch 32, Average Loss: 0.4719\n",
            "Epoch 33, Average Loss: 0.4422\n",
            "Epoch 34, Average Loss: 0.3316\n",
            "Epoch 35, Average Loss: 0.7161\n",
            "Epoch 36, Average Loss: 0.3404\n",
            "Epoch 37, Average Loss: 0.1901\n",
            "Epoch 38, Average Loss: 0.3597\n",
            "Epoch 39, Average Loss: 0.3242\n",
            "Epoch 40, Average Loss: 0.1297\n",
            "Epoch 41, Average Loss: 0.1756\n",
            "Epoch 42, Average Loss: 0.1404\n",
            "Epoch 43, Average Loss: 0.2167\n",
            "Epoch 44, Average Loss: 0.1333\n",
            "Epoch 45, Average Loss: 0.1141\n",
            "Epoch 46, Average Loss: 0.0867\n",
            "Epoch 47, Average Loss: 0.0746\n",
            "Epoch 48, Average Loss: 0.1197\n",
            "Epoch 49, Average Loss: 0.0894\n",
            "Epoch 50, Average Loss: 0.0880\n",
            "Epoch 51, Average Loss: 0.0921\n",
            "Epoch 52, Average Loss: 0.0935\n",
            "Epoch 53, Average Loss: 0.1112\n",
            "Epoch 54, Average Loss: 0.1040\n",
            "Epoch 55, Average Loss: 0.1290\n",
            "Epoch 56, Average Loss: 0.1338\n",
            "Epoch 57, Average Loss: 0.0749\n",
            "Epoch 58, Average Loss: 0.1136\n",
            "Epoch 59, Average Loss: 0.0862\n",
            "Epoch 60, Average Loss: 0.0684\n",
            "Epoch 61, Average Loss: 0.0597\n",
            "Epoch 62, Average Loss: 0.0555\n",
            "Epoch 63, Average Loss: 0.0503\n",
            "Epoch 64, Average Loss: 0.0434\n",
            "Epoch 65, Average Loss: 0.0560\n",
            "Epoch 66, Average Loss: 0.0400\n",
            "Epoch 67, Average Loss: 0.0461\n",
            "Epoch 68, Average Loss: 0.0447\n",
            "Epoch 69, Average Loss: 0.0439\n",
            "Epoch 70, Average Loss: 0.0390\n",
            "Epoch 71, Average Loss: 0.0354\n",
            "Epoch 72, Average Loss: 0.0361\n",
            "Epoch 73, Average Loss: 0.0360\n",
            "Epoch 74, Average Loss: 0.0376\n",
            "Epoch 75, Average Loss: 0.0322\n",
            "Epoch 76, Average Loss: 0.0386\n",
            "Epoch 77, Average Loss: 0.0332\n",
            "Epoch 78, Average Loss: 0.0380\n",
            "Epoch 79, Average Loss: 0.0395\n",
            "Epoch 80, Average Loss: 0.0322\n",
            "Epoch 81, Average Loss: 0.0344\n",
            "Epoch 82, Average Loss: 0.0290\n",
            "Epoch 83, Average Loss: 0.0305\n",
            "Epoch 84, Average Loss: 0.0269\n",
            "Epoch 85, Average Loss: 0.0268\n",
            "Epoch 86, Average Loss: 0.0268\n",
            "Epoch 87, Average Loss: 0.0303\n",
            "Epoch 88, Average Loss: 0.0248\n",
            "Epoch 89, Average Loss: 0.0275\n",
            "Epoch 90, Average Loss: 0.0277\n",
            "Epoch 91, Average Loss: 0.0261\n",
            "Epoch 92, Average Loss: 0.0261\n",
            "Epoch 93, Average Loss: 0.0264\n",
            "Epoch 94, Average Loss: 0.0323\n",
            "Epoch 95, Average Loss: 0.0221\n",
            "Epoch 96, Average Loss: 0.0323\n",
            "Epoch 97, Average Loss: 0.0263\n",
            "Epoch 98, Average Loss: 0.0234\n",
            "Epoch 99, Average Loss: 0.0231\n",
            "Epoch 100, Average Loss: 0.0201\n",
            "Epoch 101, Average Loss: 0.0231\n",
            "Epoch 102, Average Loss: 0.0221\n",
            "Epoch 103, Average Loss: 0.0240\n",
            "Epoch 104, Average Loss: 0.0220\n",
            "Epoch 105, Average Loss: 0.0278\n",
            "Epoch 106, Average Loss: 0.0322\n",
            "Epoch 107, Average Loss: 0.0213\n",
            "Epoch 108, Average Loss: 0.0372\n",
            "Epoch 109, Average Loss: 0.0174\n",
            "Epoch 110, Average Loss: 0.0309\n",
            "Epoch 111, Average Loss: 0.0184\n",
            "Epoch 112, Average Loss: 0.0331\n",
            "Epoch 113, Average Loss: 0.0261\n",
            "Epoch 114, Average Loss: 0.0189\n",
            "Epoch 115, Average Loss: 0.0180\n",
            "Epoch 116, Average Loss: 0.0215\n",
            "Epoch 117, Average Loss: 0.0222\n",
            "Epoch 118, Average Loss: 0.0168\n",
            "Epoch 119, Average Loss: 0.0254\n",
            "Epoch 120, Average Loss: 0.0184\n",
            "Epoch 121, Average Loss: 0.0384\n",
            "Epoch 122, Average Loss: 0.0228\n",
            "Epoch 123, Average Loss: 0.0181\n",
            "Epoch 124, Average Loss: 0.0174\n",
            "Epoch 125, Average Loss: 0.0198\n",
            "Epoch 126, Average Loss: 0.0215\n",
            "Epoch 127, Average Loss: 0.0156\n",
            "Epoch 128, Average Loss: 0.0253\n",
            "Epoch 129, Average Loss: 0.0156\n",
            "Epoch 130, Average Loss: 0.0281\n",
            "Epoch 131, Average Loss: 0.0229\n",
            "Epoch 132, Average Loss: 0.0163\n",
            "Epoch 133, Average Loss: 0.0157\n",
            "Epoch 134, Average Loss: 0.0178\n",
            "Epoch 135, Average Loss: 0.0155\n",
            "Epoch 136, Average Loss: 0.0182\n",
            "Epoch 137, Average Loss: 0.0149\n",
            "Epoch 138, Average Loss: 0.0146\n",
            "Epoch 139, Average Loss: 0.0125\n",
            "Epoch 140, Average Loss: 0.0149\n",
            "Epoch 141, Average Loss: 0.0135\n",
            "Epoch 142, Average Loss: 0.0128\n",
            "Epoch 143, Average Loss: 0.0119\n",
            "Epoch 144, Average Loss: 0.0130\n",
            "Epoch 145, Average Loss: 0.0119\n",
            "Epoch 146, Average Loss: 0.0126\n",
            "Epoch 147, Average Loss: 0.0132\n",
            "Epoch 148, Average Loss: 0.0119\n",
            "Epoch 149, Average Loss: 0.0130\n",
            "Epoch 150, Average Loss: 0.0115\n",
            "Epoch 151, Average Loss: 0.0115\n",
            "Epoch 152, Average Loss: 0.0116\n",
            "Epoch 153, Average Loss: 0.0110\n",
            "Epoch 154, Average Loss: 0.0104\n",
            "Epoch 155, Average Loss: 0.0116\n",
            "Epoch 156, Average Loss: 0.0112\n",
            "Epoch 157, Average Loss: 0.0142\n",
            "Epoch 158, Average Loss: 0.0111\n",
            "Epoch 159, Average Loss: 0.0138\n",
            "Epoch 160, Average Loss: 0.0104\n",
            "Epoch 161, Average Loss: 0.0126\n",
            "Epoch 162, Average Loss: 0.0104\n",
            "Epoch 163, Average Loss: 0.0118\n",
            "Epoch 164, Average Loss: 0.0100\n",
            "Epoch 165, Average Loss: 0.0130\n",
            "Epoch 166, Average Loss: 0.0103\n",
            "Epoch 167, Average Loss: 0.0115\n",
            "Epoch 168, Average Loss: 0.0098\n",
            "Epoch 169, Average Loss: 0.0113\n",
            "Epoch 170, Average Loss: 0.0100\n",
            "Epoch 171, Average Loss: 0.0100\n",
            "Epoch 172, Average Loss: 0.0095\n",
            "Epoch 173, Average Loss: 0.0094\n",
            "Epoch 174, Average Loss: 0.0090\n",
            "Epoch 175, Average Loss: 0.0094\n",
            "Epoch 176, Average Loss: 0.0091\n",
            "Epoch 177, Average Loss: 0.0093\n",
            "Epoch 178, Average Loss: 0.0094\n",
            "Epoch 179, Average Loss: 0.0104\n",
            "Epoch 180, Average Loss: 0.0084\n",
            "Epoch 181, Average Loss: 0.0088\n",
            "Epoch 182, Average Loss: 0.0082\n",
            "Epoch 183, Average Loss: 0.0091\n",
            "Epoch 184, Average Loss: 0.0086\n",
            "Epoch 185, Average Loss: 0.0095\n",
            "Epoch 186, Average Loss: 0.0076\n",
            "Epoch 187, Average Loss: 0.0088\n",
            "Epoch 188, Average Loss: 0.0093\n",
            "Epoch 189, Average Loss: 0.0082\n",
            "Epoch 190, Average Loss: 0.0082\n",
            "Epoch 191, Average Loss: 0.0092\n",
            "Epoch 192, Average Loss: 0.0076\n",
            "Epoch 193, Average Loss: 0.0080\n",
            "Epoch 194, Average Loss: 0.0078\n",
            "Epoch 195, Average Loss: 0.0075\n",
            "Epoch 196, Average Loss: 0.0091\n",
            "Epoch 197, Average Loss: 0.0074\n",
            "Epoch 198, Average Loss: 0.0071\n",
            "Epoch 199, Average Loss: 0.0076\n",
            "Epoch 200, Average Loss: 0.0076\n",
            "Epoch 201, Average Loss: 0.0075\n",
            "Epoch 202, Average Loss: 0.0072\n",
            "Epoch 203, Average Loss: 0.0069\n",
            "Epoch 204, Average Loss: 0.0073\n",
            "Epoch 205, Average Loss: 0.0072\n",
            "Epoch 206, Average Loss: 0.0081\n",
            "Epoch 207, Average Loss: 0.0075\n",
            "Epoch 208, Average Loss: 0.0077\n",
            "Epoch 209, Average Loss: 0.0070\n",
            "Epoch 210, Average Loss: 0.0083\n",
            "Epoch 211, Average Loss: 0.0073\n",
            "Epoch 212, Average Loss: 0.0069\n",
            "Epoch 213, Average Loss: 0.0065\n",
            "Epoch 214, Average Loss: 0.0069\n",
            "Epoch 215, Average Loss: 0.0065\n",
            "Epoch 216, Average Loss: 0.0063\n",
            "Epoch 217, Average Loss: 0.0070\n",
            "Epoch 218, Average Loss: 0.0064\n",
            "Epoch 219, Average Loss: 0.0074\n",
            "Epoch 220, Average Loss: 0.0065\n",
            "Epoch 221, Average Loss: 0.0067\n",
            "Epoch 222, Average Loss: 0.0062\n",
            "Epoch 223, Average Loss: 0.0065\n",
            "Epoch 224, Average Loss: 0.0071\n",
            "Epoch 225, Average Loss: 0.0069\n",
            "Epoch 226, Average Loss: 0.0078\n",
            "Epoch 227, Average Loss: 0.0061\n",
            "Epoch 228, Average Loss: 0.0068\n",
            "Epoch 229, Average Loss: 0.0073\n",
            "Epoch 230, Average Loss: 0.0063\n",
            "Epoch 231, Average Loss: 0.0081\n",
            "Epoch 232, Average Loss: 0.0066\n",
            "Epoch 233, Average Loss: 0.0139\n",
            "Epoch 234, Average Loss: 0.0076\n",
            "Epoch 235, Average Loss: 0.0132\n",
            "Epoch 236, Average Loss: 0.0058\n",
            "Epoch 237, Average Loss: 0.0400\n",
            "Epoch 238, Average Loss: 0.0073\n",
            "Epoch 239, Average Loss: 0.0113\n",
            "Epoch 240, Average Loss: 0.0081\n",
            "Epoch 241, Average Loss: 0.0111\n",
            "Epoch 242, Average Loss: 0.0055\n",
            "Epoch 243, Average Loss: 0.0093\n",
            "Epoch 244, Average Loss: 0.0062\n",
            "Epoch 245, Average Loss: 0.0116\n",
            "Epoch 246, Average Loss: 0.0075\n",
            "Epoch 247, Average Loss: 0.0084\n",
            "Epoch 248, Average Loss: 0.0066\n",
            "Epoch 249, Average Loss: 0.0084\n",
            "Epoch 250, Average Loss: 0.0063\n",
            "Epoch 251, Average Loss: 0.0180\n",
            "Epoch 252, Average Loss: 0.0165\n",
            "Epoch 253, Average Loss: 0.0064\n",
            "Epoch 254, Average Loss: 0.0060\n",
            "Epoch 255, Average Loss: 0.0077\n",
            "Epoch 256, Average Loss: 0.0055\n",
            "Epoch 257, Average Loss: 0.0068\n",
            "Epoch 258, Average Loss: 0.0055\n",
            "Epoch 259, Average Loss: 0.0069\n",
            "Epoch 260, Average Loss: 0.0049\n",
            "Epoch 261, Average Loss: 0.0065\n",
            "Epoch 262, Average Loss: 0.0054\n",
            "Epoch 263, Average Loss: 0.0059\n",
            "Epoch 264, Average Loss: 0.0056\n",
            "Epoch 265, Average Loss: 0.0049\n",
            "Epoch 266, Average Loss: 0.0049\n",
            "Epoch 267, Average Loss: 0.0051\n",
            "Epoch 268, Average Loss: 0.0047\n",
            "Epoch 269, Average Loss: 0.0049\n",
            "Epoch 270, Average Loss: 0.0050\n",
            "Epoch 271, Average Loss: 0.0045\n",
            "Epoch 272, Average Loss: 0.0043\n",
            "Epoch 273, Average Loss: 0.0053\n",
            "Epoch 274, Average Loss: 0.0054\n",
            "Epoch 275, Average Loss: 0.0050\n",
            "Epoch 276, Average Loss: 0.0056\n",
            "Epoch 277, Average Loss: 0.0058\n",
            "Epoch 278, Average Loss: 0.0055\n",
            "Epoch 279, Average Loss: 0.0043\n",
            "Epoch 280, Average Loss: 0.0048\n",
            "Epoch 281, Average Loss: 0.0045\n",
            "Epoch 282, Average Loss: 0.0045\n",
            "Epoch 283, Average Loss: 0.0046\n",
            "Epoch 284, Average Loss: 0.0045\n",
            "Epoch 285, Average Loss: 0.0048\n",
            "Epoch 286, Average Loss: 0.0045\n",
            "Epoch 287, Average Loss: 0.0044\n",
            "Epoch 288, Average Loss: 0.0043\n",
            "Epoch 289, Average Loss: 0.0040\n",
            "Epoch 290, Average Loss: 0.0039\n",
            "Epoch 291, Average Loss: 0.0039\n",
            "Epoch 292, Average Loss: 0.0043\n",
            "Epoch 293, Average Loss: 0.0044\n",
            "Epoch 294, Average Loss: 0.0038\n",
            "Epoch 295, Average Loss: 0.0044\n",
            "Epoch 296, Average Loss: 0.0045\n",
            "Epoch 297, Average Loss: 0.0039\n",
            "Epoch 298, Average Loss: 0.0041\n",
            "Epoch 299, Average Loss: 0.0039\n",
            "Epoch 300, Average Loss: 0.0038\n",
            "Epoch 301, Average Loss: 0.0038\n",
            "Epoch 302, Average Loss: 0.0039\n",
            "Epoch 303, Average Loss: 0.0038\n",
            "Epoch 304, Average Loss: 0.0040\n",
            "Epoch 305, Average Loss: 0.0041\n",
            "Epoch 306, Average Loss: 0.0043\n",
            "Epoch 307, Average Loss: 0.0036\n",
            "Epoch 308, Average Loss: 0.0040\n",
            "Epoch 309, Average Loss: 0.0035\n",
            "Epoch 310, Average Loss: 0.0040\n",
            "Epoch 311, Average Loss: 0.0035\n",
            "Epoch 312, Average Loss: 0.0037\n",
            "Epoch 313, Average Loss: 0.0040\n",
            "Epoch 314, Average Loss: 0.0038\n",
            "Epoch 315, Average Loss: 0.0041\n",
            "Epoch 316, Average Loss: 0.0036\n",
            "Epoch 317, Average Loss: 0.0041\n",
            "Epoch 318, Average Loss: 0.0035\n",
            "Epoch 319, Average Loss: 0.0034\n",
            "Epoch 320, Average Loss: 0.0040\n",
            "Epoch 321, Average Loss: 0.0033\n",
            "Epoch 322, Average Loss: 0.0035\n",
            "Epoch 323, Average Loss: 0.0032\n",
            "Epoch 324, Average Loss: 0.0031\n",
            "Epoch 325, Average Loss: 0.0033\n",
            "Epoch 326, Average Loss: 0.0035\n",
            "Epoch 327, Average Loss: 0.0033\n",
            "Epoch 328, Average Loss: 0.0035\n",
            "Epoch 329, Average Loss: 0.0038\n",
            "Epoch 330, Average Loss: 0.0037\n",
            "Epoch 331, Average Loss: 0.0035\n",
            "Epoch 332, Average Loss: 0.0035\n",
            "Epoch 333, Average Loss: 0.0034\n",
            "Epoch 334, Average Loss: 0.0031\n",
            "Epoch 335, Average Loss: 0.0035\n",
            "Epoch 336, Average Loss: 0.0031\n",
            "Epoch 337, Average Loss: 0.0031\n",
            "Epoch 338, Average Loss: 0.0031\n",
            "Epoch 339, Average Loss: 0.0029\n",
            "Epoch 340, Average Loss: 0.0035\n",
            "Epoch 341, Average Loss: 0.0030\n",
            "Epoch 342, Average Loss: 0.0035\n",
            "Epoch 343, Average Loss: 0.0033\n",
            "Epoch 344, Average Loss: 0.0030\n",
            "Epoch 345, Average Loss: 0.0030\n",
            "Epoch 346, Average Loss: 0.0029\n",
            "Epoch 347, Average Loss: 0.0030\n",
            "Epoch 348, Average Loss: 0.0028\n",
            "Epoch 349, Average Loss: 0.0031\n",
            "Epoch 350, Average Loss: 0.0029\n",
            "Epoch 351, Average Loss: 0.0030\n",
            "Epoch 352, Average Loss: 0.0033\n",
            "Epoch 353, Average Loss: 0.0029\n",
            "Epoch 354, Average Loss: 0.0030\n",
            "Epoch 355, Average Loss: 0.0030\n",
            "Epoch 356, Average Loss: 0.0029\n",
            "Epoch 357, Average Loss: 0.0028\n",
            "Epoch 358, Average Loss: 0.0027\n",
            "Epoch 359, Average Loss: 0.0027\n",
            "Epoch 360, Average Loss: 0.0027\n",
            "Epoch 361, Average Loss: 0.0028\n",
            "Epoch 362, Average Loss: 0.0030\n",
            "Epoch 363, Average Loss: 0.0029\n",
            "Epoch 364, Average Loss: 0.0029\n",
            "Epoch 365, Average Loss: 0.0024\n",
            "Epoch 366, Average Loss: 0.0024\n",
            "Epoch 367, Average Loss: 0.0024\n",
            "Epoch 368, Average Loss: 0.0028\n",
            "Epoch 369, Average Loss: 0.0024\n",
            "Epoch 370, Average Loss: 0.0025\n",
            "Epoch 371, Average Loss: 0.0025\n",
            "Epoch 372, Average Loss: 0.0023\n",
            "Epoch 373, Average Loss: 0.0024\n",
            "Epoch 374, Average Loss: 0.0027\n",
            "Epoch 375, Average Loss: 0.0023\n",
            "Epoch 376, Average Loss: 0.0025\n",
            "Epoch 377, Average Loss: 0.0024\n",
            "Epoch 378, Average Loss: 0.0025\n",
            "Epoch 379, Average Loss: 0.0023\n",
            "Epoch 380, Average Loss: 0.0022\n",
            "Epoch 381, Average Loss: 0.0024\n",
            "Epoch 382, Average Loss: 0.0023\n",
            "Epoch 383, Average Loss: 0.0025\n",
            "Epoch 384, Average Loss: 0.0023\n",
            "Epoch 385, Average Loss: 0.0023\n",
            "Epoch 386, Average Loss: 0.0026\n",
            "Epoch 387, Average Loss: 0.0022\n",
            "Epoch 388, Average Loss: 0.0023\n",
            "Epoch 389, Average Loss: 0.0023\n",
            "Epoch 390, Average Loss: 0.0021\n",
            "Epoch 391, Average Loss: 0.0021\n",
            "Epoch 392, Average Loss: 0.0022\n",
            "Epoch 393, Average Loss: 0.0023\n",
            "Epoch 394, Average Loss: 0.0024\n",
            "Epoch 395, Average Loss: 0.0022\n",
            "Epoch 396, Average Loss: 0.0021\n",
            "Epoch 397, Average Loss: 0.0021\n",
            "Epoch 398, Average Loss: 0.0021\n",
            "Epoch 399, Average Loss: 0.0025\n",
            "Epoch 400, Average Loss: 0.0021\n",
            "Epoch 401, Average Loss: 0.0021\n",
            "Epoch 402, Average Loss: 0.0020\n",
            "Epoch 403, Average Loss: 0.0021\n",
            "Epoch 404, Average Loss: 0.0024\n",
            "Epoch 405, Average Loss: 0.0020\n",
            "Epoch 406, Average Loss: 0.0021\n",
            "Epoch 407, Average Loss: 0.0021\n",
            "Epoch 408, Average Loss: 0.0020\n",
            "Epoch 409, Average Loss: 0.0019\n",
            "Epoch 410, Average Loss: 0.0020\n",
            "Epoch 411, Average Loss: 0.0020\n",
            "Epoch 412, Average Loss: 0.0018\n",
            "Epoch 413, Average Loss: 0.0022\n",
            "Epoch 414, Average Loss: 0.0019\n",
            "Epoch 415, Average Loss: 0.0019\n",
            "Epoch 416, Average Loss: 0.0021\n",
            "Epoch 417, Average Loss: 0.0020\n",
            "Epoch 418, Average Loss: 0.0019\n",
            "Epoch 419, Average Loss: 0.0018\n",
            "Epoch 420, Average Loss: 0.0018\n",
            "Epoch 421, Average Loss: 0.0018\n",
            "Epoch 422, Average Loss: 0.0018\n",
            "Epoch 423, Average Loss: 0.0020\n",
            "Epoch 424, Average Loss: 0.0019\n",
            "Epoch 425, Average Loss: 0.0019\n",
            "Epoch 426, Average Loss: 0.0021\n",
            "Epoch 427, Average Loss: 0.0020\n",
            "Epoch 428, Average Loss: 0.0018\n",
            "Epoch 429, Average Loss: 0.0017\n",
            "Epoch 430, Average Loss: 0.0019\n",
            "Epoch 431, Average Loss: 0.0018\n",
            "Epoch 432, Average Loss: 0.0017\n",
            "Epoch 433, Average Loss: 0.0017\n",
            "Epoch 434, Average Loss: 0.0017\n",
            "Epoch 435, Average Loss: 0.0018\n",
            "Epoch 436, Average Loss: 0.0015\n",
            "Epoch 437, Average Loss: 0.0017\n",
            "Epoch 438, Average Loss: 0.0018\n",
            "Epoch 439, Average Loss: 0.0017\n",
            "Epoch 440, Average Loss: 0.0020\n",
            "Epoch 441, Average Loss: 0.0017\n",
            "Epoch 442, Average Loss: 0.0016\n",
            "Epoch 443, Average Loss: 0.0016\n",
            "Epoch 444, Average Loss: 0.0017\n",
            "Epoch 445, Average Loss: 0.0016\n",
            "Epoch 446, Average Loss: 0.0016\n",
            "Epoch 447, Average Loss: 0.0018\n",
            "Epoch 448, Average Loss: 0.0015\n",
            "Epoch 449, Average Loss: 0.0015\n",
            "Epoch 450, Average Loss: 0.0018\n",
            "Epoch 451, Average Loss: 0.0017\n",
            "Epoch 452, Average Loss: 0.0015\n",
            "Epoch 453, Average Loss: 0.0017\n",
            "Epoch 454, Average Loss: 0.0015\n",
            "Epoch 455, Average Loss: 0.0016\n",
            "Epoch 456, Average Loss: 0.0017\n",
            "Epoch 457, Average Loss: 0.0014\n",
            "Epoch 458, Average Loss: 0.0014\n",
            "Epoch 459, Average Loss: 0.0016\n",
            "Epoch 460, Average Loss: 0.0015\n",
            "Epoch 461, Average Loss: 0.0017\n",
            "Epoch 462, Average Loss: 0.0015\n",
            "Epoch 463, Average Loss: 0.0017\n",
            "Epoch 464, Average Loss: 0.0015\n",
            "Epoch 465, Average Loss: 0.0016\n",
            "Epoch 466, Average Loss: 0.0016\n",
            "Epoch 467, Average Loss: 0.0015\n",
            "Epoch 468, Average Loss: 0.0016\n",
            "Epoch 469, Average Loss: 0.0014\n",
            "Epoch 470, Average Loss: 0.0014\n",
            "Epoch 471, Average Loss: 0.0016\n",
            "Epoch 472, Average Loss: 0.0014\n",
            "Epoch 473, Average Loss: 0.0014\n",
            "Epoch 474, Average Loss: 0.0014\n",
            "Epoch 475, Average Loss: 0.0013\n",
            "Epoch 476, Average Loss: 0.0015\n",
            "Epoch 477, Average Loss: 0.0013\n",
            "Epoch 478, Average Loss: 0.0014\n",
            "Epoch 479, Average Loss: 0.0013\n",
            "Epoch 480, Average Loss: 0.0014\n",
            "Epoch 481, Average Loss: 0.0013\n",
            "Epoch 482, Average Loss: 0.0013\n",
            "Epoch 483, Average Loss: 0.0013\n",
            "Epoch 484, Average Loss: 0.0013\n",
            "Epoch 485, Average Loss: 0.0012\n",
            "Epoch 486, Average Loss: 0.0013\n",
            "Epoch 487, Average Loss: 0.0013\n",
            "Epoch 488, Average Loss: 0.0013\n",
            "Epoch 489, Average Loss: 0.0014\n",
            "Epoch 490, Average Loss: 0.0014\n",
            "Epoch 491, Average Loss: 0.0014\n",
            "Epoch 492, Average Loss: 0.0013\n",
            "Epoch 493, Average Loss: 0.0012\n",
            "Epoch 494, Average Loss: 0.0014\n",
            "Epoch 495, Average Loss: 0.0016\n",
            "Epoch 496, Average Loss: 0.0012\n",
            "Epoch 497, Average Loss: 0.0015\n",
            "Epoch 498, Average Loss: 0.0012\n",
            "Epoch 499, Average Loss: 0.0016\n",
            "Epoch 500, Average Loss: 0.0012\n",
            "Fold 1/5\n",
            "Node-level Accuracy: 0.9375, Graph-level Accuracy: 0.9333\n",
            "Epoch 1, Average Loss: 3.7636\n",
            "Epoch 2, Average Loss: 0.8107\n",
            "Epoch 3, Average Loss: 0.5776\n",
            "Epoch 4, Average Loss: 1.2249\n",
            "Epoch 5, Average Loss: 0.6163\n",
            "Epoch 6, Average Loss: 0.5660\n",
            "Epoch 7, Average Loss: 0.2253\n",
            "Epoch 8, Average Loss: 0.2842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9, Average Loss: 0.1841\n",
            "Epoch 10, Average Loss: 0.1361\n",
            "Epoch 11, Average Loss: 0.0999\n",
            "Epoch 12, Average Loss: 0.0936\n",
            "Epoch 13, Average Loss: 0.1051\n",
            "Epoch 14, Average Loss: 0.0922\n",
            "Epoch 15, Average Loss: 0.0790\n",
            "Epoch 16, Average Loss: 0.0610\n",
            "Epoch 17, Average Loss: 0.0604\n",
            "Epoch 18, Average Loss: 0.0668\n",
            "Epoch 19, Average Loss: 0.0416\n",
            "Epoch 20, Average Loss: 0.0408\n",
            "Epoch 21, Average Loss: 0.0353\n",
            "Epoch 22, Average Loss: 0.0348\n",
            "Epoch 23, Average Loss: 0.0393\n",
            "Epoch 24, Average Loss: 0.0550\n",
            "Epoch 25, Average Loss: 0.0465\n",
            "Epoch 26, Average Loss: 0.0311\n",
            "Epoch 27, Average Loss: 0.0363\n",
            "Epoch 28, Average Loss: 0.0267\n",
            "Epoch 29, Average Loss: 0.0451\n",
            "Epoch 30, Average Loss: 0.0553\n",
            "Epoch 31, Average Loss: 0.0282\n",
            "Epoch 32, Average Loss: 0.0242\n",
            "Epoch 33, Average Loss: 0.0310\n",
            "Epoch 34, Average Loss: 0.0232\n",
            "Epoch 35, Average Loss: 0.0374\n",
            "Epoch 36, Average Loss: 0.0424\n",
            "Epoch 37, Average Loss: 0.0218\n",
            "Epoch 38, Average Loss: 0.0909\n",
            "Epoch 39, Average Loss: 0.0309\n",
            "Epoch 40, Average Loss: 0.0578\n",
            "Epoch 41, Average Loss: 0.0398\n",
            "Epoch 42, Average Loss: 0.0612\n",
            "Epoch 43, Average Loss: 0.0255\n",
            "Epoch 44, Average Loss: 0.0346\n",
            "Epoch 45, Average Loss: 0.0509\n",
            "Epoch 46, Average Loss: 0.0313\n",
            "Epoch 47, Average Loss: 0.0537\n",
            "Epoch 48, Average Loss: 0.0354\n",
            "Epoch 49, Average Loss: 0.0245\n",
            "Epoch 50, Average Loss: 0.0299\n",
            "Epoch 51, Average Loss: 0.0261\n",
            "Epoch 52, Average Loss: 0.0201\n",
            "Epoch 53, Average Loss: 0.0213\n",
            "Epoch 54, Average Loss: 0.0217\n",
            "Epoch 55, Average Loss: 0.0255\n",
            "Epoch 56, Average Loss: 0.0193\n",
            "Epoch 57, Average Loss: 0.0282\n",
            "Epoch 58, Average Loss: 0.0202\n",
            "Epoch 59, Average Loss: 0.0195\n",
            "Epoch 60, Average Loss: 0.0165\n",
            "Epoch 61, Average Loss: 0.0247\n",
            "Epoch 62, Average Loss: 0.0209\n",
            "Epoch 63, Average Loss: 0.0261\n",
            "Epoch 64, Average Loss: 0.0169\n",
            "Epoch 65, Average Loss: 0.0246\n",
            "Epoch 66, Average Loss: 0.0165\n",
            "Epoch 67, Average Loss: 0.0171\n",
            "Epoch 68, Average Loss: 0.0196\n",
            "Epoch 69, Average Loss: 0.0172\n",
            "Epoch 70, Average Loss: 0.0263\n",
            "Epoch 71, Average Loss: 0.0301\n",
            "Epoch 72, Average Loss: 0.0171\n",
            "Epoch 73, Average Loss: 0.0176\n",
            "Epoch 74, Average Loss: 0.0176\n",
            "Epoch 75, Average Loss: 0.0170\n",
            "Epoch 76, Average Loss: 0.0145\n",
            "Epoch 77, Average Loss: 0.0141\n",
            "Epoch 78, Average Loss: 0.0145\n",
            "Epoch 79, Average Loss: 0.0142\n",
            "Epoch 80, Average Loss: 0.0135\n",
            "Epoch 81, Average Loss: 0.0117\n",
            "Epoch 82, Average Loss: 0.0167\n",
            "Epoch 83, Average Loss: 0.0198\n",
            "Epoch 84, Average Loss: 0.0145\n",
            "Epoch 85, Average Loss: 0.0337\n",
            "Epoch 86, Average Loss: 0.0151\n",
            "Epoch 87, Average Loss: 0.0132\n",
            "Epoch 88, Average Loss: 0.0182\n",
            "Epoch 89, Average Loss: 0.0162\n",
            "Epoch 90, Average Loss: 0.0134\n",
            "Epoch 91, Average Loss: 0.0145\n",
            "Epoch 92, Average Loss: 0.0156\n",
            "Epoch 93, Average Loss: 0.0135\n",
            "Epoch 94, Average Loss: 0.0120\n",
            "Epoch 95, Average Loss: 0.0125\n",
            "Epoch 96, Average Loss: 0.0165\n",
            "Epoch 97, Average Loss: 0.0131\n",
            "Epoch 98, Average Loss: 0.0127\n",
            "Epoch 99, Average Loss: 0.0151\n",
            "Epoch 100, Average Loss: 0.0123\n",
            "Epoch 101, Average Loss: 0.0175\n",
            "Epoch 102, Average Loss: 0.0128\n",
            "Epoch 103, Average Loss: 0.0118\n",
            "Epoch 104, Average Loss: 0.0150\n",
            "Epoch 105, Average Loss: 0.0125\n",
            "Epoch 106, Average Loss: 0.0118\n",
            "Epoch 107, Average Loss: 0.0124\n",
            "Epoch 108, Average Loss: 0.0115\n",
            "Epoch 109, Average Loss: 0.0102\n",
            "Epoch 110, Average Loss: 0.0125\n",
            "Epoch 111, Average Loss: 0.0105\n",
            "Epoch 112, Average Loss: 0.0115\n",
            "Epoch 113, Average Loss: 0.0107\n",
            "Epoch 114, Average Loss: 0.0106\n",
            "Epoch 115, Average Loss: 0.0116\n",
            "Epoch 116, Average Loss: 0.0103\n",
            "Epoch 117, Average Loss: 0.0123\n",
            "Epoch 118, Average Loss: 0.0118\n",
            "Epoch 119, Average Loss: 0.0173\n",
            "Epoch 120, Average Loss: 0.0088\n",
            "Epoch 121, Average Loss: 0.0179\n",
            "Epoch 122, Average Loss: 0.0100\n",
            "Epoch 123, Average Loss: 0.0154\n",
            "Epoch 124, Average Loss: 0.0168\n",
            "Epoch 125, Average Loss: 0.0117\n",
            "Epoch 126, Average Loss: 0.0117\n",
            "Epoch 127, Average Loss: 0.0123\n",
            "Epoch 128, Average Loss: 0.0095\n",
            "Epoch 129, Average Loss: 0.0134\n",
            "Epoch 130, Average Loss: 0.0112\n",
            "Epoch 131, Average Loss: 0.0090\n",
            "Epoch 132, Average Loss: 0.0100\n",
            "Epoch 133, Average Loss: 0.0113\n",
            "Epoch 134, Average Loss: 0.0122\n",
            "Epoch 135, Average Loss: 0.0104\n",
            "Epoch 136, Average Loss: 0.0085\n",
            "Epoch 137, Average Loss: 0.0092\n",
            "Epoch 138, Average Loss: 0.0099\n",
            "Epoch 139, Average Loss: 0.0139\n",
            "Epoch 140, Average Loss: 0.0108\n",
            "Epoch 141, Average Loss: 0.0124\n",
            "Epoch 142, Average Loss: 0.0131\n",
            "Epoch 143, Average Loss: 0.0088\n",
            "Epoch 144, Average Loss: 0.0116\n",
            "Epoch 145, Average Loss: 0.0096\n",
            "Epoch 146, Average Loss: 0.0084\n",
            "Epoch 147, Average Loss: 0.0094\n",
            "Epoch 148, Average Loss: 0.0085\n",
            "Epoch 149, Average Loss: 0.0088\n",
            "Epoch 150, Average Loss: 0.0079\n",
            "Epoch 151, Average Loss: 0.0085\n",
            "Epoch 152, Average Loss: 0.0083\n",
            "Epoch 153, Average Loss: 0.0079\n",
            "Epoch 154, Average Loss: 0.0099\n",
            "Epoch 155, Average Loss: 0.0083\n",
            "Epoch 156, Average Loss: 0.0088\n",
            "Epoch 157, Average Loss: 0.0079\n",
            "Epoch 158, Average Loss: 0.0091\n",
            "Epoch 159, Average Loss: 0.0084\n",
            "Epoch 160, Average Loss: 0.0083\n",
            "Epoch 161, Average Loss: 0.0088\n",
            "Epoch 162, Average Loss: 0.0078\n",
            "Epoch 163, Average Loss: 0.0075\n",
            "Epoch 164, Average Loss: 0.0076\n",
            "Epoch 165, Average Loss: 0.0077\n",
            "Epoch 166, Average Loss: 0.0075\n",
            "Epoch 167, Average Loss: 0.0084\n",
            "Epoch 168, Average Loss: 0.0081\n",
            "Epoch 169, Average Loss: 0.0082\n",
            "Epoch 170, Average Loss: 0.0106\n",
            "Epoch 171, Average Loss: 0.0080\n",
            "Epoch 172, Average Loss: 0.0078\n",
            "Epoch 173, Average Loss: 0.0071\n",
            "Epoch 174, Average Loss: 0.0073\n",
            "Epoch 175, Average Loss: 0.0075\n",
            "Epoch 176, Average Loss: 0.0082\n",
            "Epoch 177, Average Loss: 0.0076\n",
            "Epoch 178, Average Loss: 0.0081\n",
            "Epoch 179, Average Loss: 0.0100\n",
            "Epoch 180, Average Loss: 0.0085\n",
            "Epoch 181, Average Loss: 0.0084\n",
            "Epoch 182, Average Loss: 0.0110\n",
            "Epoch 183, Average Loss: 0.0074\n",
            "Epoch 184, Average Loss: 0.0079\n",
            "Epoch 185, Average Loss: 0.0087\n",
            "Epoch 186, Average Loss: 0.0068\n",
            "Epoch 187, Average Loss: 0.0072\n",
            "Epoch 188, Average Loss: 0.0066\n",
            "Epoch 189, Average Loss: 0.0080\n",
            "Epoch 190, Average Loss: 0.0068\n",
            "Epoch 191, Average Loss: 0.0063\n",
            "Epoch 192, Average Loss: 0.0064\n",
            "Epoch 193, Average Loss: 0.0060\n",
            "Epoch 194, Average Loss: 0.0087\n",
            "Epoch 195, Average Loss: 0.0074\n",
            "Epoch 196, Average Loss: 0.0066\n",
            "Epoch 197, Average Loss: 0.0110\n",
            "Epoch 198, Average Loss: 0.0076\n",
            "Epoch 199, Average Loss: 0.0132\n",
            "Epoch 200, Average Loss: 0.0144\n",
            "Epoch 201, Average Loss: 0.0066\n",
            "Epoch 202, Average Loss: 0.0116\n",
            "Epoch 203, Average Loss: 0.0112\n",
            "Epoch 204, Average Loss: 0.0059\n",
            "Epoch 205, Average Loss: 0.0070\n",
            "Epoch 206, Average Loss: 0.0073\n",
            "Epoch 207, Average Loss: 0.0062\n",
            "Epoch 208, Average Loss: 0.0071\n",
            "Epoch 209, Average Loss: 0.0069\n",
            "Epoch 210, Average Loss: 0.0061\n",
            "Epoch 211, Average Loss: 0.0076\n",
            "Epoch 212, Average Loss: 0.0069\n",
            "Epoch 213, Average Loss: 0.0089\n",
            "Epoch 214, Average Loss: 0.0067\n",
            "Epoch 215, Average Loss: 0.0075\n",
            "Epoch 216, Average Loss: 0.0060\n",
            "Epoch 217, Average Loss: 0.0060\n",
            "Epoch 218, Average Loss: 0.0063\n",
            "Epoch 219, Average Loss: 0.0059\n",
            "Epoch 220, Average Loss: 0.0063\n",
            "Epoch 221, Average Loss: 0.0055\n",
            "Epoch 222, Average Loss: 0.0061\n",
            "Epoch 223, Average Loss: 0.0054\n",
            "Epoch 224, Average Loss: 0.0056\n",
            "Epoch 225, Average Loss: 0.0062\n",
            "Epoch 226, Average Loss: 0.0054\n",
            "Epoch 227, Average Loss: 0.0052\n",
            "Epoch 228, Average Loss: 0.0059\n",
            "Epoch 229, Average Loss: 0.0052\n",
            "Epoch 230, Average Loss: 0.0053\n",
            "Epoch 231, Average Loss: 0.0052\n",
            "Epoch 232, Average Loss: 0.0051\n",
            "Epoch 233, Average Loss: 0.0052\n",
            "Epoch 234, Average Loss: 0.0063\n",
            "Epoch 235, Average Loss: 0.0056\n",
            "Epoch 236, Average Loss: 0.0066\n",
            "Epoch 237, Average Loss: 0.0051\n",
            "Epoch 238, Average Loss: 0.0061\n",
            "Epoch 239, Average Loss: 0.0049\n",
            "Epoch 240, Average Loss: 0.0049\n",
            "Epoch 241, Average Loss: 0.0060\n",
            "Epoch 242, Average Loss: 0.0050\n",
            "Epoch 243, Average Loss: 0.0080\n",
            "Epoch 244, Average Loss: 0.0051\n",
            "Epoch 245, Average Loss: 0.0063\n",
            "Epoch 246, Average Loss: 0.0097\n",
            "Epoch 247, Average Loss: 0.0077\n",
            "Epoch 248, Average Loss: 0.0056\n",
            "Epoch 249, Average Loss: 0.0067\n",
            "Epoch 250, Average Loss: 0.0055\n",
            "Epoch 251, Average Loss: 0.0051\n",
            "Epoch 252, Average Loss: 0.0097\n",
            "Epoch 253, Average Loss: 0.0044\n",
            "Epoch 254, Average Loss: 0.0371\n",
            "Epoch 255, Average Loss: 0.0131\n",
            "Epoch 256, Average Loss: 0.0053\n",
            "Epoch 257, Average Loss: 0.0061\n",
            "Epoch 258, Average Loss: 0.0074\n",
            "Epoch 259, Average Loss: 0.0083\n",
            "Epoch 260, Average Loss: 0.0150\n",
            "Epoch 261, Average Loss: 0.0128\n",
            "Epoch 262, Average Loss: 0.0052\n",
            "Epoch 263, Average Loss: 0.0060\n",
            "Epoch 264, Average Loss: 0.0046\n",
            "Epoch 265, Average Loss: 0.0049\n",
            "Epoch 266, Average Loss: 0.0049\n",
            "Epoch 267, Average Loss: 0.0044\n",
            "Epoch 268, Average Loss: 0.0042\n",
            "Epoch 269, Average Loss: 0.0040\n",
            "Epoch 270, Average Loss: 0.0040\n",
            "Epoch 271, Average Loss: 0.0041\n",
            "Epoch 272, Average Loss: 0.0041\n",
            "Epoch 273, Average Loss: 0.0041\n",
            "Epoch 274, Average Loss: 0.0044\n",
            "Epoch 275, Average Loss: 0.0037\n",
            "Epoch 276, Average Loss: 0.0042\n",
            "Epoch 277, Average Loss: 0.0037\n",
            "Epoch 278, Average Loss: 0.0044\n",
            "Epoch 279, Average Loss: 0.0037\n",
            "Epoch 280, Average Loss: 0.0036\n",
            "Epoch 281, Average Loss: 0.0051\n",
            "Epoch 282, Average Loss: 0.0050\n",
            "Epoch 283, Average Loss: 0.0037\n",
            "Epoch 284, Average Loss: 0.0033\n",
            "Epoch 285, Average Loss: 0.0042\n",
            "Epoch 286, Average Loss: 0.0032\n",
            "Epoch 287, Average Loss: 0.0034\n",
            "Epoch 288, Average Loss: 0.0034\n",
            "Epoch 289, Average Loss: 0.0034\n",
            "Epoch 290, Average Loss: 0.0031\n",
            "Epoch 291, Average Loss: 0.0031\n",
            "Epoch 292, Average Loss: 0.0033\n",
            "Epoch 293, Average Loss: 0.0034\n",
            "Epoch 294, Average Loss: 0.0034\n",
            "Epoch 295, Average Loss: 0.0032\n",
            "Epoch 296, Average Loss: 0.0033\n",
            "Epoch 297, Average Loss: 0.0030\n",
            "Epoch 298, Average Loss: 0.0030\n",
            "Epoch 299, Average Loss: 0.0030\n",
            "Epoch 300, Average Loss: 0.0034\n",
            "Epoch 301, Average Loss: 0.0036\n",
            "Epoch 302, Average Loss: 0.0029\n",
            "Epoch 303, Average Loss: 0.0041\n",
            "Epoch 304, Average Loss: 0.0032\n",
            "Epoch 305, Average Loss: 0.0036\n",
            "Epoch 306, Average Loss: 0.0027\n",
            "Epoch 307, Average Loss: 0.0031\n",
            "Epoch 308, Average Loss: 0.0027\n",
            "Epoch 309, Average Loss: 0.0026\n",
            "Epoch 310, Average Loss: 0.0024\n",
            "Epoch 311, Average Loss: 0.0028\n",
            "Epoch 312, Average Loss: 0.0026\n",
            "Epoch 313, Average Loss: 0.0028\n",
            "Epoch 314, Average Loss: 0.0025\n",
            "Epoch 315, Average Loss: 0.0028\n",
            "Epoch 316, Average Loss: 0.0023\n",
            "Epoch 317, Average Loss: 0.0026\n",
            "Epoch 318, Average Loss: 0.0025\n",
            "Epoch 319, Average Loss: 0.0024\n",
            "Epoch 320, Average Loss: 0.0024\n",
            "Epoch 321, Average Loss: 0.0026\n",
            "Epoch 322, Average Loss: 0.0022\n",
            "Epoch 323, Average Loss: 0.0025\n",
            "Epoch 324, Average Loss: 0.0025\n",
            "Epoch 325, Average Loss: 0.0025\n",
            "Epoch 326, Average Loss: 0.0024\n",
            "Epoch 327, Average Loss: 0.0022\n",
            "Epoch 328, Average Loss: 0.0022\n",
            "Epoch 329, Average Loss: 0.0025\n",
            "Epoch 330, Average Loss: 0.0023\n",
            "Epoch 331, Average Loss: 0.0026\n",
            "Epoch 332, Average Loss: 0.0025\n",
            "Epoch 333, Average Loss: 0.0025\n",
            "Epoch 334, Average Loss: 0.0023\n",
            "Epoch 335, Average Loss: 0.0025\n",
            "Epoch 336, Average Loss: 0.0024\n",
            "Epoch 337, Average Loss: 0.0025\n",
            "Epoch 338, Average Loss: 0.0022\n",
            "Epoch 339, Average Loss: 0.0024\n",
            "Epoch 340, Average Loss: 0.0023\n",
            "Epoch 341, Average Loss: 0.0021\n",
            "Epoch 342, Average Loss: 0.0021\n",
            "Epoch 343, Average Loss: 0.0025\n",
            "Epoch 344, Average Loss: 0.0022\n",
            "Epoch 345, Average Loss: 0.0025\n",
            "Epoch 346, Average Loss: 0.0022\n",
            "Epoch 347, Average Loss: 0.0024\n",
            "Epoch 348, Average Loss: 0.0021\n",
            "Epoch 349, Average Loss: 0.0020\n",
            "Epoch 350, Average Loss: 0.0022\n",
            "Epoch 351, Average Loss: 0.0021\n",
            "Epoch 352, Average Loss: 0.0021\n",
            "Epoch 353, Average Loss: 0.0021\n",
            "Epoch 354, Average Loss: 0.0020\n",
            "Epoch 355, Average Loss: 0.0020\n",
            "Epoch 356, Average Loss: 0.0022\n",
            "Epoch 357, Average Loss: 0.0020\n",
            "Epoch 358, Average Loss: 0.0019\n",
            "Epoch 359, Average Loss: 0.0020\n",
            "Epoch 360, Average Loss: 0.0020\n",
            "Epoch 361, Average Loss: 0.0019\n",
            "Epoch 362, Average Loss: 0.0018\n",
            "Epoch 363, Average Loss: 0.0020\n",
            "Epoch 364, Average Loss: 0.0018\n",
            "Epoch 365, Average Loss: 0.0022\n",
            "Epoch 366, Average Loss: 0.0021\n",
            "Epoch 367, Average Loss: 0.0019\n",
            "Epoch 368, Average Loss: 0.0020\n",
            "Epoch 369, Average Loss: 0.0019\n",
            "Epoch 370, Average Loss: 0.0019\n",
            "Epoch 371, Average Loss: 0.0018\n",
            "Epoch 372, Average Loss: 0.0019\n",
            "Epoch 373, Average Loss: 0.0018\n",
            "Epoch 374, Average Loss: 0.0019\n",
            "Epoch 375, Average Loss: 0.0018\n",
            "Epoch 376, Average Loss: 0.0020\n",
            "Epoch 377, Average Loss: 0.0019\n",
            "Epoch 378, Average Loss: 0.0019\n",
            "Epoch 379, Average Loss: 0.0017\n",
            "Epoch 380, Average Loss: 0.0020\n",
            "Epoch 381, Average Loss: 0.0019\n",
            "Epoch 382, Average Loss: 0.0017\n",
            "Epoch 383, Average Loss: 0.0019\n",
            "Epoch 384, Average Loss: 0.0019\n",
            "Epoch 385, Average Loss: 0.0017\n",
            "Epoch 386, Average Loss: 0.0016\n",
            "Epoch 387, Average Loss: 0.0016\n",
            "Epoch 388, Average Loss: 0.0017\n",
            "Epoch 389, Average Loss: 0.0018\n",
            "Epoch 390, Average Loss: 0.0016\n",
            "Epoch 391, Average Loss: 0.0017\n",
            "Epoch 392, Average Loss: 0.0016\n",
            "Epoch 393, Average Loss: 0.0017\n",
            "Epoch 394, Average Loss: 0.0019\n",
            "Epoch 395, Average Loss: 0.0017\n",
            "Epoch 396, Average Loss: 0.0019\n",
            "Epoch 397, Average Loss: 0.0016\n",
            "Epoch 398, Average Loss: 0.0020\n",
            "Epoch 399, Average Loss: 0.0019\n",
            "Epoch 400, Average Loss: 0.0018\n",
            "Epoch 401, Average Loss: 0.0017\n",
            "Epoch 402, Average Loss: 0.0016\n",
            "Epoch 403, Average Loss: 0.0015\n",
            "Epoch 404, Average Loss: 0.0016\n",
            "Epoch 405, Average Loss: 0.0016\n",
            "Epoch 406, Average Loss: 0.0015\n",
            "Epoch 407, Average Loss: 0.0015\n",
            "Epoch 408, Average Loss: 0.0017\n",
            "Epoch 409, Average Loss: 0.0016\n",
            "Epoch 410, Average Loss: 0.0015\n",
            "Epoch 411, Average Loss: 0.0015\n",
            "Epoch 412, Average Loss: 0.0015\n",
            "Epoch 413, Average Loss: 0.0014\n",
            "Epoch 414, Average Loss: 0.0016\n",
            "Epoch 415, Average Loss: 0.0015\n",
            "Epoch 416, Average Loss: 0.0014\n",
            "Epoch 417, Average Loss: 0.0016\n",
            "Epoch 418, Average Loss: 0.0015\n",
            "Epoch 419, Average Loss: 0.0014\n",
            "Epoch 420, Average Loss: 0.0015\n",
            "Epoch 421, Average Loss: 0.0015\n",
            "Epoch 422, Average Loss: 0.0015\n",
            "Epoch 423, Average Loss: 0.0014\n",
            "Epoch 424, Average Loss: 0.0014\n",
            "Epoch 425, Average Loss: 0.0016\n",
            "Epoch 426, Average Loss: 0.0014\n",
            "Epoch 427, Average Loss: 0.0018\n",
            "Epoch 428, Average Loss: 0.0014\n",
            "Epoch 429, Average Loss: 0.0014\n",
            "Epoch 430, Average Loss: 0.0014\n",
            "Epoch 431, Average Loss: 0.0014\n",
            "Epoch 432, Average Loss: 0.0017\n",
            "Epoch 433, Average Loss: 0.0014\n",
            "Epoch 434, Average Loss: 0.0014\n",
            "Epoch 435, Average Loss: 0.0014\n",
            "Epoch 436, Average Loss: 0.0013\n",
            "Epoch 437, Average Loss: 0.0016\n",
            "Epoch 438, Average Loss: 0.0014\n",
            "Epoch 439, Average Loss: 0.0014\n",
            "Epoch 440, Average Loss: 0.0013\n",
            "Epoch 441, Average Loss: 0.0014\n",
            "Epoch 442, Average Loss: 0.0015\n",
            "Epoch 443, Average Loss: 0.0013\n",
            "Epoch 444, Average Loss: 0.0013\n",
            "Epoch 445, Average Loss: 0.0013\n",
            "Epoch 446, Average Loss: 0.0013\n",
            "Epoch 447, Average Loss: 0.0015\n",
            "Epoch 448, Average Loss: 0.0014\n",
            "Epoch 449, Average Loss: 0.0013\n",
            "Epoch 450, Average Loss: 0.0013\n",
            "Epoch 451, Average Loss: 0.0014\n",
            "Epoch 452, Average Loss: 0.0014\n",
            "Epoch 453, Average Loss: 0.0014\n",
            "Epoch 454, Average Loss: 0.0013\n",
            "Epoch 455, Average Loss: 0.0013\n",
            "Epoch 456, Average Loss: 0.0013\n",
            "Epoch 457, Average Loss: 0.0013\n",
            "Epoch 458, Average Loss: 0.0013\n",
            "Epoch 459, Average Loss: 0.0013\n",
            "Epoch 460, Average Loss: 0.0012\n",
            "Epoch 461, Average Loss: 0.0014\n",
            "Epoch 462, Average Loss: 0.0012\n",
            "Epoch 463, Average Loss: 0.0015\n",
            "Epoch 464, Average Loss: 0.0012\n",
            "Epoch 465, Average Loss: 0.0013\n",
            "Epoch 466, Average Loss: 0.0012\n",
            "Epoch 467, Average Loss: 0.0013\n",
            "Epoch 468, Average Loss: 0.0012\n",
            "Epoch 469, Average Loss: 0.0015\n",
            "Epoch 470, Average Loss: 0.0012\n",
            "Epoch 471, Average Loss: 0.0013\n",
            "Epoch 472, Average Loss: 0.0011\n",
            "Epoch 473, Average Loss: 0.0011\n",
            "Epoch 474, Average Loss: 0.0013\n",
            "Epoch 475, Average Loss: 0.0013\n",
            "Epoch 476, Average Loss: 0.0014\n",
            "Epoch 477, Average Loss: 0.0014\n",
            "Epoch 478, Average Loss: 0.0013\n",
            "Epoch 479, Average Loss: 0.0012\n",
            "Epoch 480, Average Loss: 0.0013\n",
            "Epoch 481, Average Loss: 0.0011\n",
            "Epoch 482, Average Loss: 0.0013\n",
            "Epoch 483, Average Loss: 0.0013\n",
            "Epoch 484, Average Loss: 0.0012\n",
            "Epoch 485, Average Loss: 0.0012\n",
            "Epoch 486, Average Loss: 0.0012\n",
            "Epoch 487, Average Loss: 0.0012\n",
            "Epoch 488, Average Loss: 0.0012\n",
            "Epoch 489, Average Loss: 0.0011\n",
            "Epoch 490, Average Loss: 0.0011\n",
            "Epoch 491, Average Loss: 0.0011\n",
            "Epoch 492, Average Loss: 0.0011\n",
            "Epoch 493, Average Loss: 0.0012\n",
            "Epoch 494, Average Loss: 0.0012\n",
            "Epoch 495, Average Loss: 0.0011\n",
            "Epoch 496, Average Loss: 0.0014\n",
            "Epoch 497, Average Loss: 0.0011\n",
            "Epoch 498, Average Loss: 0.0014\n",
            "Epoch 499, Average Loss: 0.0012\n",
            "Epoch 500, Average Loss: 0.0011\n",
            "Fold 2/5\n",
            "Node-level Accuracy: 0.9556, Graph-level Accuracy: 0.8667\n",
            "Epoch 1, Average Loss: 9.3888\n",
            "Epoch 2, Average Loss: 0.5106\n",
            "Epoch 3, Average Loss: 0.4411\n",
            "Epoch 4, Average Loss: 1.1939\n",
            "Epoch 5, Average Loss: 0.3905\n",
            "Epoch 6, Average Loss: 0.4009\n",
            "Epoch 7, Average Loss: 0.5094\n",
            "Epoch 8, Average Loss: 0.3815\n",
            "Epoch 9, Average Loss: 0.1738\n",
            "Epoch 10, Average Loss: 0.2272\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11, Average Loss: 0.3149\n",
            "Epoch 12, Average Loss: 0.1349\n",
            "Epoch 13, Average Loss: 0.1525\n",
            "Epoch 14, Average Loss: 0.1154\n",
            "Epoch 15, Average Loss: 0.1241\n",
            "Epoch 16, Average Loss: 0.0841\n",
            "Epoch 17, Average Loss: 0.0791\n",
            "Epoch 18, Average Loss: 0.0745\n",
            "Epoch 19, Average Loss: 0.0756\n",
            "Epoch 20, Average Loss: 0.0672\n",
            "Epoch 21, Average Loss: 0.0581\n",
            "Epoch 22, Average Loss: 0.0760\n",
            "Epoch 23, Average Loss: 0.0496\n",
            "Epoch 24, Average Loss: 0.0604\n",
            "Epoch 25, Average Loss: 0.0511\n",
            "Epoch 26, Average Loss: 0.0473\n",
            "Epoch 27, Average Loss: 0.0502\n",
            "Epoch 28, Average Loss: 0.0423\n",
            "Epoch 29, Average Loss: 0.0480\n",
            "Epoch 30, Average Loss: 0.0407\n",
            "Epoch 31, Average Loss: 0.0516\n",
            "Epoch 32, Average Loss: 0.0453\n",
            "Epoch 33, Average Loss: 0.0389\n",
            "Epoch 34, Average Loss: 0.0391\n",
            "Epoch 35, Average Loss: 0.0442\n",
            "Epoch 36, Average Loss: 0.0408\n",
            "Epoch 37, Average Loss: 0.0400\n",
            "Epoch 38, Average Loss: 0.0401\n",
            "Epoch 39, Average Loss: 0.0375\n",
            "Epoch 40, Average Loss: 0.0462\n",
            "Epoch 41, Average Loss: 0.0414\n",
            "Epoch 42, Average Loss: 0.0431\n",
            "Epoch 43, Average Loss: 0.0477\n",
            "Epoch 44, Average Loss: 0.0366\n",
            "Epoch 45, Average Loss: 0.0362\n",
            "Epoch 46, Average Loss: 0.0378\n",
            "Epoch 47, Average Loss: 0.0376\n",
            "Epoch 48, Average Loss: 0.0408\n",
            "Epoch 49, Average Loss: 0.0381\n",
            "Epoch 50, Average Loss: 0.0589\n",
            "Epoch 51, Average Loss: 0.0390\n",
            "Epoch 52, Average Loss: 0.0455\n",
            "Epoch 53, Average Loss: 0.0468\n",
            "Epoch 54, Average Loss: 0.0353\n",
            "Epoch 55, Average Loss: 0.0506\n",
            "Epoch 56, Average Loss: 0.0381\n",
            "Epoch 57, Average Loss: 0.0389\n",
            "Epoch 58, Average Loss: 0.0360\n",
            "Epoch 59, Average Loss: 0.0365\n",
            "Epoch 60, Average Loss: 0.0339\n",
            "Epoch 61, Average Loss: 0.0367\n",
            "Epoch 62, Average Loss: 0.0349\n",
            "Epoch 63, Average Loss: 0.0330\n",
            "Epoch 64, Average Loss: 0.0402\n",
            "Epoch 65, Average Loss: 0.0315\n",
            "Epoch 66, Average Loss: 0.0504\n",
            "Epoch 67, Average Loss: 0.0307\n",
            "Epoch 68, Average Loss: 0.0510\n",
            "Epoch 69, Average Loss: 0.0432\n",
            "Epoch 70, Average Loss: 0.0291\n",
            "Epoch 71, Average Loss: 0.0355\n",
            "Epoch 72, Average Loss: 0.0380\n",
            "Epoch 73, Average Loss: 0.0355\n",
            "Epoch 74, Average Loss: 0.0314\n",
            "Epoch 75, Average Loss: 0.0305\n",
            "Epoch 76, Average Loss: 0.0392\n",
            "Epoch 77, Average Loss: 0.0309\n",
            "Epoch 78, Average Loss: 0.0312\n",
            "Epoch 79, Average Loss: 0.0300\n",
            "Epoch 80, Average Loss: 0.0314\n",
            "Epoch 81, Average Loss: 0.0426\n",
            "Epoch 82, Average Loss: 0.0310\n",
            "Epoch 83, Average Loss: 0.0327\n",
            "Epoch 84, Average Loss: 0.0319\n",
            "Epoch 85, Average Loss: 0.0304\n",
            "Epoch 86, Average Loss: 0.0260\n",
            "Epoch 87, Average Loss: 0.0347\n",
            "Epoch 88, Average Loss: 0.0306\n",
            "Epoch 89, Average Loss: 0.0350\n",
            "Epoch 90, Average Loss: 0.0285\n",
            "Epoch 91, Average Loss: 0.0294\n",
            "Epoch 92, Average Loss: 0.0334\n",
            "Epoch 93, Average Loss: 0.0287\n",
            "Epoch 94, Average Loss: 0.0279\n",
            "Epoch 95, Average Loss: 0.0274\n",
            "Epoch 96, Average Loss: 0.0272\n",
            "Epoch 97, Average Loss: 0.0278\n",
            "Epoch 98, Average Loss: 0.0257\n",
            "Epoch 99, Average Loss: 0.0274\n",
            "Epoch 100, Average Loss: 0.0272\n",
            "Epoch 101, Average Loss: 0.0306\n",
            "Epoch 102, Average Loss: 0.0257\n",
            "Epoch 103, Average Loss: 0.0332\n",
            "Epoch 104, Average Loss: 0.0259\n",
            "Epoch 105, Average Loss: 0.0314\n",
            "Epoch 106, Average Loss: 0.0258\n",
            "Epoch 107, Average Loss: 0.0275\n",
            "Epoch 108, Average Loss: 0.0288\n",
            "Epoch 109, Average Loss: 0.0244\n",
            "Epoch 110, Average Loss: 0.0242\n",
            "Epoch 111, Average Loss: 0.0257\n",
            "Epoch 112, Average Loss: 0.0269\n",
            "Epoch 113, Average Loss: 0.0269\n",
            "Epoch 114, Average Loss: 0.0259\n",
            "Epoch 115, Average Loss: 0.0245\n",
            "Epoch 116, Average Loss: 0.0271\n",
            "Epoch 117, Average Loss: 0.0331\n",
            "Epoch 118, Average Loss: 0.0262\n",
            "Epoch 119, Average Loss: 0.0256\n",
            "Epoch 120, Average Loss: 0.0309\n",
            "Epoch 121, Average Loss: 0.0259\n",
            "Epoch 122, Average Loss: 0.0251\n",
            "Epoch 123, Average Loss: 0.0312\n",
            "Epoch 124, Average Loss: 0.0240\n",
            "Epoch 125, Average Loss: 0.0277\n",
            "Epoch 126, Average Loss: 0.0279\n",
            "Epoch 127, Average Loss: 0.0258\n",
            "Epoch 128, Average Loss: 0.0253\n",
            "Epoch 129, Average Loss: 0.0268\n",
            "Epoch 130, Average Loss: 0.0250\n",
            "Epoch 131, Average Loss: 0.0249\n",
            "Epoch 132, Average Loss: 0.0244\n",
            "Epoch 133, Average Loss: 0.0257\n",
            "Epoch 134, Average Loss: 0.0239\n",
            "Epoch 135, Average Loss: 0.0234\n",
            "Epoch 136, Average Loss: 0.0241\n",
            "Epoch 137, Average Loss: 0.0261\n",
            "Epoch 138, Average Loss: 0.0302\n",
            "Epoch 139, Average Loss: 0.0252\n",
            "Epoch 140, Average Loss: 0.0270\n",
            "Epoch 141, Average Loss: 0.0242\n",
            "Epoch 142, Average Loss: 0.0246\n",
            "Epoch 143, Average Loss: 0.0294\n",
            "Epoch 144, Average Loss: 0.0226\n",
            "Epoch 145, Average Loss: 0.0248\n",
            "Epoch 146, Average Loss: 0.0211\n",
            "Epoch 147, Average Loss: 0.0172\n",
            "Epoch 148, Average Loss: 0.0199\n",
            "Epoch 149, Average Loss: 0.0154\n",
            "Epoch 150, Average Loss: 0.0183\n",
            "Epoch 151, Average Loss: 0.0137\n",
            "Epoch 152, Average Loss: 0.0129\n",
            "Epoch 153, Average Loss: 0.0149\n",
            "Epoch 154, Average Loss: 0.0107\n",
            "Epoch 155, Average Loss: 0.0135\n",
            "Epoch 156, Average Loss: 0.0115\n",
            "Epoch 157, Average Loss: 0.0109\n",
            "Epoch 158, Average Loss: 0.0120\n",
            "Epoch 159, Average Loss: 0.0130\n",
            "Epoch 160, Average Loss: 0.0130\n",
            "Epoch 161, Average Loss: 0.0113\n",
            "Epoch 162, Average Loss: 0.0101\n",
            "Epoch 163, Average Loss: 0.0093\n",
            "Epoch 164, Average Loss: 0.0093\n",
            "Epoch 165, Average Loss: 0.0106\n",
            "Epoch 166, Average Loss: 0.0111\n",
            "Epoch 167, Average Loss: 0.0095\n",
            "Epoch 168, Average Loss: 0.0099\n",
            "Epoch 169, Average Loss: 0.0097\n",
            "Epoch 170, Average Loss: 0.0085\n",
            "Epoch 171, Average Loss: 0.0087\n",
            "Epoch 172, Average Loss: 0.0089\n",
            "Epoch 173, Average Loss: 0.0083\n",
            "Epoch 174, Average Loss: 0.0083\n",
            "Epoch 175, Average Loss: 0.0080\n",
            "Epoch 176, Average Loss: 0.0095\n",
            "Epoch 177, Average Loss: 0.0079\n",
            "Epoch 178, Average Loss: 0.0085\n",
            "Epoch 179, Average Loss: 0.0085\n",
            "Epoch 180, Average Loss: 0.0081\n",
            "Epoch 181, Average Loss: 0.0077\n",
            "Epoch 182, Average Loss: 0.0075\n",
            "Epoch 183, Average Loss: 0.0072\n",
            "Epoch 184, Average Loss: 0.0075\n",
            "Epoch 185, Average Loss: 0.0085\n",
            "Epoch 186, Average Loss: 0.0064\n",
            "Epoch 187, Average Loss: 0.0071\n",
            "Epoch 188, Average Loss: 0.0066\n",
            "Epoch 189, Average Loss: 0.0064\n",
            "Epoch 190, Average Loss: 0.0065\n",
            "Epoch 191, Average Loss: 0.0071\n",
            "Epoch 192, Average Loss: 0.0068\n",
            "Epoch 193, Average Loss: 0.0060\n",
            "Epoch 194, Average Loss: 0.0065\n",
            "Epoch 195, Average Loss: 0.0064\n",
            "Epoch 196, Average Loss: 0.0059\n",
            "Epoch 197, Average Loss: 0.0061\n",
            "Epoch 198, Average Loss: 0.0065\n",
            "Epoch 199, Average Loss: 0.0062\n",
            "Epoch 200, Average Loss: 0.0067\n",
            "Epoch 201, Average Loss: 0.0058\n",
            "Epoch 202, Average Loss: 0.0059\n",
            "Epoch 203, Average Loss: 0.0059\n",
            "Epoch 204, Average Loss: 0.0059\n",
            "Epoch 205, Average Loss: 0.0054\n",
            "Epoch 206, Average Loss: 0.0068\n",
            "Epoch 207, Average Loss: 0.0055\n",
            "Epoch 208, Average Loss: 0.0055\n",
            "Epoch 209, Average Loss: 0.0061\n",
            "Epoch 210, Average Loss: 0.0056\n",
            "Epoch 211, Average Loss: 0.0054\n",
            "Epoch 212, Average Loss: 0.0051\n",
            "Epoch 213, Average Loss: 0.0051\n",
            "Epoch 214, Average Loss: 0.0050\n",
            "Epoch 215, Average Loss: 0.0049\n",
            "Epoch 216, Average Loss: 0.0054\n",
            "Epoch 217, Average Loss: 0.0058\n",
            "Epoch 218, Average Loss: 0.0050\n",
            "Epoch 219, Average Loss: 0.0059\n",
            "Epoch 220, Average Loss: 0.0055\n",
            "Epoch 221, Average Loss: 0.0049\n",
            "Epoch 222, Average Loss: 0.0049\n",
            "Epoch 223, Average Loss: 0.0049\n",
            "Epoch 224, Average Loss: 0.0045\n",
            "Epoch 225, Average Loss: 0.0053\n",
            "Epoch 226, Average Loss: 0.0050\n",
            "Epoch 227, Average Loss: 0.0046\n",
            "Epoch 228, Average Loss: 0.0048\n",
            "Epoch 229, Average Loss: 0.0048\n",
            "Epoch 230, Average Loss: 0.0042\n",
            "Epoch 231, Average Loss: 0.0047\n",
            "Epoch 232, Average Loss: 0.0046\n",
            "Epoch 233, Average Loss: 0.0048\n",
            "Epoch 234, Average Loss: 0.0044\n",
            "Epoch 235, Average Loss: 0.0049\n",
            "Epoch 236, Average Loss: 0.0044\n",
            "Epoch 237, Average Loss: 0.0047\n",
            "Epoch 238, Average Loss: 0.0045\n",
            "Epoch 239, Average Loss: 0.0046\n",
            "Epoch 240, Average Loss: 0.0042\n",
            "Epoch 241, Average Loss: 0.0041\n",
            "Epoch 242, Average Loss: 0.0046\n",
            "Epoch 243, Average Loss: 0.0041\n",
            "Epoch 244, Average Loss: 0.0044\n",
            "Epoch 245, Average Loss: 0.0044\n",
            "Epoch 246, Average Loss: 0.0040\n",
            "Epoch 247, Average Loss: 0.0040\n",
            "Epoch 248, Average Loss: 0.0038\n",
            "Epoch 249, Average Loss: 0.0045\n",
            "Epoch 250, Average Loss: 0.0038\n",
            "Epoch 251, Average Loss: 0.0040\n",
            "Epoch 252, Average Loss: 0.0047\n",
            "Epoch 253, Average Loss: 0.0038\n",
            "Epoch 254, Average Loss: 0.0037\n",
            "Epoch 255, Average Loss: 0.0040\n",
            "Epoch 256, Average Loss: 0.0036\n",
            "Epoch 257, Average Loss: 0.0039\n",
            "Epoch 258, Average Loss: 0.0038\n",
            "Epoch 259, Average Loss: 0.0040\n",
            "Epoch 260, Average Loss: 0.0035\n",
            "Epoch 261, Average Loss: 0.0038\n",
            "Epoch 262, Average Loss: 0.0037\n",
            "Epoch 263, Average Loss: 0.0035\n",
            "Epoch 264, Average Loss: 0.0038\n",
            "Epoch 265, Average Loss: 0.0037\n",
            "Epoch 266, Average Loss: 0.0034\n",
            "Epoch 267, Average Loss: 0.0036\n",
            "Epoch 268, Average Loss: 0.0038\n",
            "Epoch 269, Average Loss: 0.0035\n",
            "Epoch 270, Average Loss: 0.0039\n",
            "Epoch 271, Average Loss: 0.0037\n",
            "Epoch 272, Average Loss: 0.0033\n",
            "Epoch 273, Average Loss: 0.0038\n",
            "Epoch 274, Average Loss: 0.0037\n",
            "Epoch 275, Average Loss: 0.0035\n",
            "Epoch 276, Average Loss: 0.0033\n",
            "Epoch 277, Average Loss: 0.0036\n",
            "Epoch 278, Average Loss: 0.0033\n",
            "Epoch 279, Average Loss: 0.0033\n",
            "Epoch 280, Average Loss: 0.0031\n",
            "Epoch 281, Average Loss: 0.0034\n",
            "Epoch 282, Average Loss: 0.0033\n",
            "Epoch 283, Average Loss: 0.0030\n",
            "Epoch 284, Average Loss: 0.0034\n",
            "Epoch 285, Average Loss: 0.0031\n",
            "Epoch 286, Average Loss: 0.0033\n",
            "Epoch 287, Average Loss: 0.0031\n",
            "Epoch 288, Average Loss: 0.0032\n",
            "Epoch 289, Average Loss: 0.0032\n",
            "Epoch 290, Average Loss: 0.0032\n",
            "Epoch 291, Average Loss: 0.0029\n",
            "Epoch 292, Average Loss: 0.0031\n",
            "Epoch 293, Average Loss: 0.0034\n",
            "Epoch 294, Average Loss: 0.0030\n",
            "Epoch 295, Average Loss: 0.0032\n",
            "Epoch 296, Average Loss: 0.0028\n",
            "Epoch 297, Average Loss: 0.0030\n",
            "Epoch 298, Average Loss: 0.0032\n",
            "Epoch 299, Average Loss: 0.0028\n",
            "Epoch 300, Average Loss: 0.0029\n",
            "Epoch 301, Average Loss: 0.0028\n",
            "Epoch 302, Average Loss: 0.0027\n",
            "Epoch 303, Average Loss: 0.0028\n",
            "Epoch 304, Average Loss: 0.0028\n",
            "Epoch 305, Average Loss: 0.0033\n",
            "Epoch 306, Average Loss: 0.0027\n",
            "Epoch 307, Average Loss: 0.0027\n",
            "Epoch 308, Average Loss: 0.0030\n",
            "Epoch 309, Average Loss: 0.0030\n",
            "Epoch 310, Average Loss: 0.0029\n",
            "Epoch 311, Average Loss: 0.0028\n",
            "Epoch 312, Average Loss: 0.0027\n",
            "Epoch 313, Average Loss: 0.0029\n",
            "Epoch 314, Average Loss: 0.0031\n",
            "Epoch 315, Average Loss: 0.0026\n",
            "Epoch 316, Average Loss: 0.0026\n",
            "Epoch 317, Average Loss: 0.0027\n",
            "Epoch 318, Average Loss: 0.0027\n",
            "Epoch 319, Average Loss: 0.0026\n",
            "Epoch 320, Average Loss: 0.0027\n",
            "Epoch 321, Average Loss: 0.0028\n",
            "Epoch 322, Average Loss: 0.0027\n",
            "Epoch 323, Average Loss: 0.0028\n",
            "Epoch 324, Average Loss: 0.0027\n",
            "Epoch 325, Average Loss: 0.0029\n",
            "Epoch 326, Average Loss: 0.0025\n",
            "Epoch 327, Average Loss: 0.0027\n",
            "Epoch 328, Average Loss: 0.0026\n",
            "Epoch 329, Average Loss: 0.0025\n",
            "Epoch 330, Average Loss: 0.0025\n",
            "Epoch 331, Average Loss: 0.0026\n",
            "Epoch 332, Average Loss: 0.0027\n",
            "Epoch 333, Average Loss: 0.0028\n",
            "Epoch 334, Average Loss: 0.0024\n",
            "Epoch 335, Average Loss: 0.0024\n",
            "Epoch 336, Average Loss: 0.0027\n",
            "Epoch 337, Average Loss: 0.0029\n",
            "Epoch 338, Average Loss: 0.0025\n",
            "Epoch 339, Average Loss: 0.0024\n",
            "Epoch 340, Average Loss: 0.0024\n",
            "Epoch 341, Average Loss: 0.0025\n",
            "Epoch 342, Average Loss: 0.0024\n",
            "Epoch 343, Average Loss: 0.0023\n",
            "Epoch 344, Average Loss: 0.0025\n",
            "Epoch 345, Average Loss: 0.0025\n",
            "Epoch 346, Average Loss: 0.0023\n",
            "Epoch 347, Average Loss: 0.0023\n",
            "Epoch 348, Average Loss: 0.0024\n",
            "Epoch 349, Average Loss: 0.0024\n",
            "Epoch 350, Average Loss: 0.0025\n",
            "Epoch 351, Average Loss: 0.0023\n",
            "Epoch 352, Average Loss: 0.0025\n",
            "Epoch 353, Average Loss: 0.0026\n",
            "Epoch 354, Average Loss: 0.0023\n",
            "Epoch 355, Average Loss: 0.0026\n",
            "Epoch 356, Average Loss: 0.0023\n",
            "Epoch 357, Average Loss: 0.0024\n",
            "Epoch 358, Average Loss: 0.0024\n",
            "Epoch 359, Average Loss: 0.0023\n",
            "Epoch 360, Average Loss: 0.0023\n",
            "Epoch 361, Average Loss: 0.0026\n",
            "Epoch 362, Average Loss: 0.0025\n",
            "Epoch 363, Average Loss: 0.0026\n",
            "Epoch 364, Average Loss: 0.0024\n",
            "Epoch 365, Average Loss: 0.0024\n",
            "Epoch 366, Average Loss: 0.0023\n",
            "Epoch 367, Average Loss: 0.0022\n",
            "Epoch 368, Average Loss: 0.0023\n",
            "Epoch 369, Average Loss: 0.0025\n",
            "Epoch 370, Average Loss: 0.0022\n",
            "Epoch 371, Average Loss: 0.0020\n",
            "Epoch 372, Average Loss: 0.0022\n",
            "Epoch 373, Average Loss: 0.0022\n",
            "Epoch 374, Average Loss: 0.0022\n",
            "Epoch 375, Average Loss: 0.0021\n",
            "Epoch 376, Average Loss: 0.0022\n",
            "Epoch 377, Average Loss: 0.0020\n",
            "Epoch 378, Average Loss: 0.0021\n",
            "Epoch 379, Average Loss: 0.0020\n",
            "Epoch 380, Average Loss: 0.0020\n",
            "Epoch 381, Average Loss: 0.0021\n",
            "Epoch 382, Average Loss: 0.0020\n",
            "Epoch 383, Average Loss: 0.0020\n",
            "Epoch 384, Average Loss: 0.0022\n",
            "Epoch 385, Average Loss: 0.0023\n",
            "Epoch 386, Average Loss: 0.0020\n",
            "Epoch 387, Average Loss: 0.0021\n",
            "Epoch 388, Average Loss: 0.0022\n",
            "Epoch 389, Average Loss: 0.0022\n",
            "Epoch 390, Average Loss: 0.0019\n",
            "Epoch 391, Average Loss: 0.0021\n",
            "Epoch 392, Average Loss: 0.0021\n",
            "Epoch 393, Average Loss: 0.0021\n",
            "Epoch 394, Average Loss: 0.0019\n",
            "Epoch 395, Average Loss: 0.0020\n",
            "Epoch 396, Average Loss: 0.0019\n",
            "Epoch 397, Average Loss: 0.0020\n",
            "Epoch 398, Average Loss: 0.0022\n",
            "Epoch 399, Average Loss: 0.0021\n",
            "Epoch 400, Average Loss: 0.0019\n",
            "Epoch 401, Average Loss: 0.0019\n",
            "Epoch 402, Average Loss: 0.0019\n",
            "Epoch 403, Average Loss: 0.0019\n",
            "Epoch 404, Average Loss: 0.0020\n",
            "Epoch 405, Average Loss: 0.0019\n",
            "Epoch 406, Average Loss: 0.0018\n",
            "Epoch 407, Average Loss: 0.0021\n",
            "Epoch 408, Average Loss: 0.0020\n",
            "Epoch 409, Average Loss: 0.0020\n",
            "Epoch 410, Average Loss: 0.0020\n",
            "Epoch 411, Average Loss: 0.0017\n",
            "Epoch 412, Average Loss: 0.0021\n",
            "Epoch 413, Average Loss: 0.0017\n",
            "Epoch 414, Average Loss: 0.0018\n",
            "Epoch 415, Average Loss: 0.0017\n",
            "Epoch 416, Average Loss: 0.0018\n",
            "Epoch 417, Average Loss: 0.0018\n",
            "Epoch 418, Average Loss: 0.0018\n",
            "Epoch 419, Average Loss: 0.0020\n",
            "Epoch 420, Average Loss: 0.0017\n",
            "Epoch 421, Average Loss: 0.0017\n",
            "Epoch 422, Average Loss: 0.0020\n",
            "Epoch 423, Average Loss: 0.0019\n",
            "Epoch 424, Average Loss: 0.0017\n",
            "Epoch 425, Average Loss: 0.0018\n",
            "Epoch 426, Average Loss: 0.0017\n",
            "Epoch 427, Average Loss: 0.0019\n",
            "Epoch 428, Average Loss: 0.0018\n",
            "Epoch 429, Average Loss: 0.0016\n",
            "Epoch 430, Average Loss: 0.0019\n",
            "Epoch 431, Average Loss: 0.0017\n",
            "Epoch 432, Average Loss: 0.0017\n",
            "Epoch 433, Average Loss: 0.0017\n",
            "Epoch 434, Average Loss: 0.0018\n",
            "Epoch 435, Average Loss: 0.0016\n",
            "Epoch 436, Average Loss: 0.0017\n",
            "Epoch 437, Average Loss: 0.0016\n",
            "Epoch 438, Average Loss: 0.0016\n",
            "Epoch 439, Average Loss: 0.0016\n",
            "Epoch 440, Average Loss: 0.0018\n",
            "Epoch 441, Average Loss: 0.0016\n",
            "Epoch 442, Average Loss: 0.0016\n",
            "Epoch 443, Average Loss: 0.0016\n",
            "Epoch 444, Average Loss: 0.0018\n",
            "Epoch 445, Average Loss: 0.0017\n",
            "Epoch 446, Average Loss: 0.0018\n",
            "Epoch 447, Average Loss: 0.0017\n",
            "Epoch 448, Average Loss: 0.0015\n",
            "Epoch 449, Average Loss: 0.0018\n",
            "Epoch 450, Average Loss: 0.0015\n",
            "Epoch 451, Average Loss: 0.0016\n",
            "Epoch 452, Average Loss: 0.0016\n",
            "Epoch 453, Average Loss: 0.0018\n",
            "Epoch 454, Average Loss: 0.0015\n",
            "Epoch 455, Average Loss: 0.0016\n",
            "Epoch 456, Average Loss: 0.0016\n",
            "Epoch 457, Average Loss: 0.0016\n",
            "Epoch 458, Average Loss: 0.0017\n",
            "Epoch 459, Average Loss: 0.0016\n",
            "Epoch 460, Average Loss: 0.0016\n",
            "Epoch 461, Average Loss: 0.0015\n",
            "Epoch 462, Average Loss: 0.0016\n",
            "Epoch 463, Average Loss: 0.0017\n",
            "Epoch 464, Average Loss: 0.0016\n",
            "Epoch 465, Average Loss: 0.0016\n",
            "Epoch 466, Average Loss: 0.0015\n",
            "Epoch 467, Average Loss: 0.0015\n",
            "Epoch 468, Average Loss: 0.0015\n",
            "Epoch 469, Average Loss: 0.0015\n",
            "Epoch 470, Average Loss: 0.0016\n",
            "Epoch 471, Average Loss: 0.0014\n",
            "Epoch 472, Average Loss: 0.0014\n",
            "Epoch 473, Average Loss: 0.0016\n",
            "Epoch 474, Average Loss: 0.0014\n",
            "Epoch 475, Average Loss: 0.0014\n",
            "Epoch 476, Average Loss: 0.0015\n",
            "Epoch 477, Average Loss: 0.0015\n",
            "Epoch 478, Average Loss: 0.0014\n",
            "Epoch 479, Average Loss: 0.0017\n",
            "Epoch 480, Average Loss: 0.0016\n",
            "Epoch 481, Average Loss: 0.0014\n",
            "Epoch 482, Average Loss: 0.0017\n",
            "Epoch 483, Average Loss: 0.0014\n",
            "Epoch 484, Average Loss: 0.0014\n",
            "Epoch 485, Average Loss: 0.0015\n",
            "Epoch 486, Average Loss: 0.0014\n",
            "Epoch 487, Average Loss: 0.0015\n",
            "Epoch 488, Average Loss: 0.0016\n",
            "Epoch 489, Average Loss: 0.0015\n",
            "Epoch 490, Average Loss: 0.0013\n",
            "Epoch 491, Average Loss: 0.0014\n",
            "Epoch 492, Average Loss: 0.0014\n",
            "Epoch 493, Average Loss: 0.0015\n",
            "Epoch 494, Average Loss: 0.0014\n",
            "Epoch 495, Average Loss: 0.0014\n",
            "Epoch 496, Average Loss: 0.0014\n",
            "Epoch 497, Average Loss: 0.0012\n",
            "Epoch 498, Average Loss: 0.0649\n",
            "Epoch 499, Average Loss: 0.2780\n",
            "Epoch 500, Average Loss: 0.1859\n",
            "Fold 3/5\n",
            "Node-level Accuracy: 0.9565, Graph-level Accuracy: 0.8667\n",
            "Epoch 1, Average Loss: 2.4126\n",
            "Epoch 2, Average Loss: 4.9490\n",
            "Epoch 3, Average Loss: 1.2985\n",
            "Epoch 4, Average Loss: 1.2206\n",
            "Epoch 5, Average Loss: 1.0293\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6, Average Loss: 0.7046\n",
            "Epoch 7, Average Loss: 0.4246\n",
            "Epoch 8, Average Loss: 0.3592\n",
            "Epoch 9, Average Loss: 1.0567\n",
            "Epoch 10, Average Loss: 0.1577\n",
            "Epoch 11, Average Loss: 0.4014\n",
            "Epoch 12, Average Loss: 0.3296\n",
            "Epoch 13, Average Loss: 0.4437\n",
            "Epoch 14, Average Loss: 0.3265\n",
            "Epoch 15, Average Loss: 0.2041\n",
            "Epoch 16, Average Loss: 0.1843\n",
            "Epoch 17, Average Loss: 0.1408\n",
            "Epoch 18, Average Loss: 0.2075\n",
            "Epoch 19, Average Loss: 0.1708\n",
            "Epoch 20, Average Loss: 0.1523\n",
            "Epoch 21, Average Loss: 0.1126\n",
            "Epoch 22, Average Loss: 0.1119\n",
            "Epoch 23, Average Loss: 0.1068\n",
            "Epoch 24, Average Loss: 0.0925\n",
            "Epoch 25, Average Loss: 0.0974\n",
            "Epoch 26, Average Loss: 0.0943\n",
            "Epoch 27, Average Loss: 0.1033\n",
            "Epoch 28, Average Loss: 0.0909\n",
            "Epoch 29, Average Loss: 0.0848\n",
            "Epoch 30, Average Loss: 0.1006\n",
            "Epoch 31, Average Loss: 0.0874\n",
            "Epoch 32, Average Loss: 0.0808\n",
            "Epoch 33, Average Loss: 0.0864\n",
            "Epoch 34, Average Loss: 0.0764\n",
            "Epoch 35, Average Loss: 0.0825\n",
            "Epoch 36, Average Loss: 0.0821\n",
            "Epoch 37, Average Loss: 0.0781\n",
            "Epoch 38, Average Loss: 0.0754\n",
            "Epoch 39, Average Loss: 0.0740\n",
            "Epoch 40, Average Loss: 0.0731\n",
            "Epoch 41, Average Loss: 0.0764\n",
            "Epoch 42, Average Loss: 0.0868\n",
            "Epoch 43, Average Loss: 0.0767\n",
            "Epoch 44, Average Loss: 0.0742\n",
            "Epoch 45, Average Loss: 0.0815\n",
            "Epoch 46, Average Loss: 0.0794\n",
            "Epoch 47, Average Loss: 0.0737\n",
            "Epoch 48, Average Loss: 0.0658\n",
            "Epoch 49, Average Loss: 0.0738\n",
            "Epoch 50, Average Loss: 0.0691\n",
            "Epoch 51, Average Loss: 0.0761\n",
            "Epoch 52, Average Loss: 0.0699\n",
            "Epoch 53, Average Loss: 0.0623\n",
            "Epoch 54, Average Loss: 0.0692\n",
            "Epoch 55, Average Loss: 0.0677\n",
            "Epoch 56, Average Loss: 0.0637\n",
            "Epoch 57, Average Loss: 0.0698\n",
            "Epoch 58, Average Loss: 0.0626\n",
            "Epoch 59, Average Loss: 0.0672\n",
            "Epoch 60, Average Loss: 0.0602\n",
            "Epoch 61, Average Loss: 0.0614\n",
            "Epoch 62, Average Loss: 0.0728\n",
            "Epoch 63, Average Loss: 0.0613\n",
            "Epoch 64, Average Loss: 0.0653\n",
            "Epoch 65, Average Loss: 0.0598\n",
            "Epoch 66, Average Loss: 0.0577\n",
            "Epoch 67, Average Loss: 0.0537\n",
            "Epoch 68, Average Loss: 0.0679\n",
            "Epoch 69, Average Loss: 0.0695\n",
            "Epoch 70, Average Loss: 0.0625\n",
            "Epoch 71, Average Loss: 0.0681\n",
            "Epoch 72, Average Loss: 0.0587\n",
            "Epoch 73, Average Loss: 0.0598\n",
            "Epoch 74, Average Loss: 0.0573\n",
            "Epoch 75, Average Loss: 0.0683\n",
            "Epoch 76, Average Loss: 0.0570\n",
            "Epoch 77, Average Loss: 0.0631\n",
            "Epoch 78, Average Loss: 0.0619\n",
            "Epoch 79, Average Loss: 0.0638\n",
            "Epoch 80, Average Loss: 0.0534\n",
            "Epoch 81, Average Loss: 0.0583\n",
            "Epoch 82, Average Loss: 0.0491\n",
            "Epoch 83, Average Loss: 0.0644\n",
            "Epoch 84, Average Loss: 0.0522\n",
            "Epoch 85, Average Loss: 0.0521\n",
            "Epoch 86, Average Loss: 0.0625\n",
            "Epoch 87, Average Loss: 0.0507\n",
            "Epoch 88, Average Loss: 0.0524\n",
            "Epoch 89, Average Loss: 0.0476\n",
            "Epoch 90, Average Loss: 0.0488\n",
            "Epoch 91, Average Loss: 0.0533\n",
            "Epoch 92, Average Loss: 0.0474\n",
            "Epoch 93, Average Loss: 0.0520\n",
            "Epoch 94, Average Loss: 0.0525\n",
            "Epoch 95, Average Loss: 0.0564\n",
            "Epoch 96, Average Loss: 0.0489\n",
            "Epoch 97, Average Loss: 0.0474\n",
            "Epoch 98, Average Loss: 0.0468\n",
            "Epoch 99, Average Loss: 0.0484\n",
            "Epoch 100, Average Loss: 0.0465\n",
            "Epoch 101, Average Loss: 0.0509\n",
            "Epoch 102, Average Loss: 0.0505\n",
            "Epoch 103, Average Loss: 0.0408\n",
            "Epoch 104, Average Loss: 0.0435\n",
            "Epoch 105, Average Loss: 0.0458\n",
            "Epoch 106, Average Loss: 0.0468\n",
            "Epoch 107, Average Loss: 0.0396\n",
            "Epoch 108, Average Loss: 0.0439\n",
            "Epoch 109, Average Loss: 0.0470\n",
            "Epoch 110, Average Loss: 0.0420\n",
            "Epoch 111, Average Loss: 0.0456\n",
            "Epoch 112, Average Loss: 0.0441\n",
            "Epoch 113, Average Loss: 0.0438\n",
            "Epoch 114, Average Loss: 0.0437\n",
            "Epoch 115, Average Loss: 0.0415\n",
            "Epoch 116, Average Loss: 0.0421\n",
            "Epoch 117, Average Loss: 0.0466\n",
            "Epoch 118, Average Loss: 0.0435\n",
            "Epoch 119, Average Loss: 0.0438\n",
            "Epoch 120, Average Loss: 0.0479\n",
            "Epoch 121, Average Loss: 0.0426\n",
            "Epoch 122, Average Loss: 0.0431\n",
            "Epoch 123, Average Loss: 0.0560\n",
            "Epoch 124, Average Loss: 0.0503\n",
            "Epoch 125, Average Loss: 0.0434\n",
            "Epoch 126, Average Loss: 0.0482\n",
            "Epoch 127, Average Loss: 0.0424\n",
            "Epoch 128, Average Loss: 0.0386\n",
            "Epoch 129, Average Loss: 0.0430\n",
            "Epoch 130, Average Loss: 0.0371\n",
            "Epoch 131, Average Loss: 0.0404\n",
            "Epoch 132, Average Loss: 0.0393\n",
            "Epoch 133, Average Loss: 0.0407\n",
            "Epoch 134, Average Loss: 0.0381\n",
            "Epoch 135, Average Loss: 0.0383\n",
            "Epoch 136, Average Loss: 0.0352\n",
            "Epoch 137, Average Loss: 0.0363\n",
            "Epoch 138, Average Loss: 0.0398\n",
            "Epoch 139, Average Loss: 0.0383\n",
            "Epoch 140, Average Loss: 0.0499\n",
            "Epoch 141, Average Loss: 0.0384\n",
            "Epoch 142, Average Loss: 0.0386\n",
            "Epoch 143, Average Loss: 0.0413\n",
            "Epoch 144, Average Loss: 0.0356\n",
            "Epoch 145, Average Loss: 0.0576\n",
            "Epoch 146, Average Loss: 0.0377\n",
            "Epoch 147, Average Loss: 0.0504\n",
            "Epoch 148, Average Loss: 0.0519\n",
            "Epoch 149, Average Loss: 0.0559\n",
            "Epoch 150, Average Loss: 0.0424\n",
            "Epoch 151, Average Loss: 0.0365\n",
            "Epoch 152, Average Loss: 0.0393\n",
            "Epoch 153, Average Loss: 0.0422\n",
            "Epoch 154, Average Loss: 0.0437\n",
            "Epoch 155, Average Loss: 0.0424\n",
            "Epoch 156, Average Loss: 0.0382\n",
            "Epoch 157, Average Loss: 0.0386\n",
            "Epoch 158, Average Loss: 0.0386\n",
            "Epoch 159, Average Loss: 0.0373\n",
            "Epoch 160, Average Loss: 0.0406\n",
            "Epoch 161, Average Loss: 0.0350\n",
            "Epoch 162, Average Loss: 0.0334\n",
            "Epoch 163, Average Loss: 0.0352\n",
            "Epoch 164, Average Loss: 0.0342\n",
            "Epoch 165, Average Loss: 0.0358\n",
            "Epoch 166, Average Loss: 0.0355\n",
            "Epoch 167, Average Loss: 0.0313\n",
            "Epoch 168, Average Loss: 0.0349\n",
            "Epoch 169, Average Loss: 0.0371\n",
            "Epoch 170, Average Loss: 0.0415\n",
            "Epoch 171, Average Loss: 0.0344\n",
            "Epoch 172, Average Loss: 0.0325\n",
            "Epoch 173, Average Loss: 0.0316\n",
            "Epoch 174, Average Loss: 0.0306\n",
            "Epoch 175, Average Loss: 0.0404\n",
            "Epoch 176, Average Loss: 0.0427\n",
            "Epoch 177, Average Loss: 0.0420\n",
            "Epoch 178, Average Loss: 0.0309\n",
            "Epoch 179, Average Loss: 0.0402\n",
            "Epoch 180, Average Loss: 0.0340\n",
            "Epoch 181, Average Loss: 0.0387\n",
            "Epoch 182, Average Loss: 0.0344\n",
            "Epoch 183, Average Loss: 0.0276\n",
            "Epoch 184, Average Loss: 0.0338\n",
            "Epoch 185, Average Loss: 0.0343\n",
            "Epoch 186, Average Loss: 0.0281\n",
            "Epoch 187, Average Loss: 0.0310\n",
            "Epoch 188, Average Loss: 0.0297\n",
            "Epoch 189, Average Loss: 0.0274\n",
            "Epoch 190, Average Loss: 0.0305\n",
            "Epoch 191, Average Loss: 0.0291\n",
            "Epoch 192, Average Loss: 0.0318\n",
            "Epoch 193, Average Loss: 0.0311\n",
            "Epoch 194, Average Loss: 0.0269\n",
            "Epoch 195, Average Loss: 0.0332\n",
            "Epoch 196, Average Loss: 0.0277\n",
            "Epoch 197, Average Loss: 0.0293\n",
            "Epoch 198, Average Loss: 0.0255\n",
            "Epoch 199, Average Loss: 0.0407\n",
            "Epoch 200, Average Loss: 0.0240\n",
            "Epoch 201, Average Loss: 0.0285\n",
            "Epoch 202, Average Loss: 0.0319\n",
            "Epoch 203, Average Loss: 0.0264\n",
            "Epoch 204, Average Loss: 0.0312\n",
            "Epoch 205, Average Loss: 0.0252\n",
            "Epoch 206, Average Loss: 0.0265\n",
            "Epoch 207, Average Loss: 0.0307\n",
            "Epoch 208, Average Loss: 0.0270\n",
            "Epoch 209, Average Loss: 0.0286\n",
            "Epoch 210, Average Loss: 0.0409\n",
            "Epoch 211, Average Loss: 0.0249\n",
            "Epoch 212, Average Loss: 0.0388\n",
            "Epoch 213, Average Loss: 0.0318\n",
            "Epoch 214, Average Loss: 0.0312\n",
            "Epoch 215, Average Loss: 0.0272\n",
            "Epoch 216, Average Loss: 0.0206\n",
            "Epoch 217, Average Loss: 0.0227\n",
            "Epoch 218, Average Loss: 0.0244\n",
            "Epoch 219, Average Loss: 0.0229\n",
            "Epoch 220, Average Loss: 0.0231\n",
            "Epoch 221, Average Loss: 0.0222\n",
            "Epoch 222, Average Loss: 0.0201\n",
            "Epoch 223, Average Loss: 0.0238\n",
            "Epoch 224, Average Loss: 0.0198\n",
            "Epoch 225, Average Loss: 0.0237\n",
            "Epoch 226, Average Loss: 0.0196\n",
            "Epoch 227, Average Loss: 0.0233\n",
            "Epoch 228, Average Loss: 0.0244\n",
            "Epoch 229, Average Loss: 0.0192\n",
            "Epoch 230, Average Loss: 0.0210\n",
            "Epoch 231, Average Loss: 0.0182\n",
            "Epoch 232, Average Loss: 0.0190\n",
            "Epoch 233, Average Loss: 0.0187\n",
            "Epoch 234, Average Loss: 0.0240\n",
            "Epoch 235, Average Loss: 0.0228\n",
            "Epoch 236, Average Loss: 0.0206\n",
            "Epoch 237, Average Loss: 0.0168\n",
            "Epoch 238, Average Loss: 0.0168\n",
            "Epoch 239, Average Loss: 0.0178\n",
            "Epoch 240, Average Loss: 0.0199\n",
            "Epoch 241, Average Loss: 0.0176\n",
            "Epoch 242, Average Loss: 0.0163\n",
            "Epoch 243, Average Loss: 0.0162\n",
            "Epoch 244, Average Loss: 0.0173\n",
            "Epoch 245, Average Loss: 0.0153\n",
            "Epoch 246, Average Loss: 0.0160\n",
            "Epoch 247, Average Loss: 0.0151\n",
            "Epoch 248, Average Loss: 0.0179\n",
            "Epoch 249, Average Loss: 0.0171\n",
            "Epoch 250, Average Loss: 0.0151\n",
            "Epoch 251, Average Loss: 0.0162\n",
            "Epoch 252, Average Loss: 0.0237\n",
            "Epoch 253, Average Loss: 0.0210\n",
            "Epoch 254, Average Loss: 0.0182\n",
            "Epoch 255, Average Loss: 0.0175\n",
            "Epoch 256, Average Loss: 0.0163\n",
            "Epoch 257, Average Loss: 0.0137\n",
            "Epoch 258, Average Loss: 0.0186\n",
            "Epoch 259, Average Loss: 0.0231\n",
            "Epoch 260, Average Loss: 0.0145\n",
            "Epoch 261, Average Loss: 0.0259\n",
            "Epoch 262, Average Loss: 0.0365\n",
            "Epoch 263, Average Loss: 0.0200\n",
            "Epoch 264, Average Loss: 0.0402\n",
            "Epoch 265, Average Loss: 0.0292\n",
            "Epoch 266, Average Loss: 0.0270\n",
            "Epoch 267, Average Loss: 0.0251\n",
            "Epoch 268, Average Loss: 0.0163\n",
            "Epoch 269, Average Loss: 0.0303\n",
            "Epoch 270, Average Loss: 0.0193\n",
            "Epoch 271, Average Loss: 0.0162\n",
            "Epoch 272, Average Loss: 0.0237\n",
            "Epoch 273, Average Loss: 0.0206\n",
            "Epoch 274, Average Loss: 0.0224\n",
            "Epoch 275, Average Loss: 0.0209\n",
            "Epoch 276, Average Loss: 0.0228\n",
            "Epoch 277, Average Loss: 0.0164\n",
            "Epoch 278, Average Loss: 0.0391\n",
            "Epoch 279, Average Loss: 0.0217\n",
            "Epoch 280, Average Loss: 0.0668\n",
            "Epoch 281, Average Loss: 0.0330\n",
            "Epoch 282, Average Loss: 0.0628\n",
            "Epoch 283, Average Loss: 0.1089\n",
            "Epoch 284, Average Loss: 0.1781\n",
            "Epoch 285, Average Loss: 0.0895\n",
            "Epoch 286, Average Loss: 0.2637\n",
            "Epoch 287, Average Loss: 0.1292\n",
            "Epoch 288, Average Loss: 0.0988\n",
            "Epoch 289, Average Loss: 0.1951\n",
            "Epoch 290, Average Loss: 0.0463\n",
            "Epoch 291, Average Loss: 0.1067\n",
            "Epoch 292, Average Loss: 0.0485\n",
            "Epoch 293, Average Loss: 0.0519\n",
            "Epoch 294, Average Loss: 0.0430\n",
            "Epoch 295, Average Loss: 0.0578\n",
            "Epoch 296, Average Loss: 0.0218\n",
            "Epoch 297, Average Loss: 0.0372\n",
            "Epoch 298, Average Loss: 0.0300\n",
            "Epoch 299, Average Loss: 0.0210\n",
            "Epoch 300, Average Loss: 0.0391\n",
            "Epoch 301, Average Loss: 0.0196\n",
            "Epoch 302, Average Loss: 0.0285\n",
            "Epoch 303, Average Loss: 0.0241\n",
            "Epoch 304, Average Loss: 0.0183\n",
            "Epoch 305, Average Loss: 0.0231\n",
            "Epoch 306, Average Loss: 0.0183\n",
            "Epoch 307, Average Loss: 0.0191\n",
            "Epoch 308, Average Loss: 0.0176\n",
            "Epoch 309, Average Loss: 0.0208\n",
            "Epoch 310, Average Loss: 0.0169\n",
            "Epoch 311, Average Loss: 0.0169\n",
            "Epoch 312, Average Loss: 0.0191\n",
            "Epoch 313, Average Loss: 0.0184\n",
            "Epoch 314, Average Loss: 0.0166\n",
            "Epoch 315, Average Loss: 0.0162\n",
            "Epoch 316, Average Loss: 0.0165\n",
            "Epoch 317, Average Loss: 0.0160\n",
            "Epoch 318, Average Loss: 0.0150\n",
            "Epoch 319, Average Loss: 0.0189\n",
            "Epoch 320, Average Loss: 0.0162\n",
            "Epoch 321, Average Loss: 0.0136\n",
            "Epoch 322, Average Loss: 0.0148\n",
            "Epoch 323, Average Loss: 0.0161\n",
            "Epoch 324, Average Loss: 0.0152\n",
            "Epoch 325, Average Loss: 0.0133\n",
            "Epoch 326, Average Loss: 0.0155\n",
            "Epoch 327, Average Loss: 0.0161\n",
            "Epoch 328, Average Loss: 0.0158\n",
            "Epoch 329, Average Loss: 0.0142\n",
            "Epoch 330, Average Loss: 0.0131\n",
            "Epoch 331, Average Loss: 0.0136\n",
            "Epoch 332, Average Loss: 0.0151\n",
            "Epoch 333, Average Loss: 0.0143\n",
            "Epoch 334, Average Loss: 0.0170\n",
            "Epoch 335, Average Loss: 0.0147\n",
            "Epoch 336, Average Loss: 0.0138\n",
            "Epoch 337, Average Loss: 0.0234\n",
            "Epoch 338, Average Loss: 0.0292\n",
            "Epoch 339, Average Loss: 0.0161\n",
            "Epoch 340, Average Loss: 0.0535\n",
            "Epoch 341, Average Loss: 0.0300\n",
            "Epoch 342, Average Loss: 0.0645\n",
            "Epoch 343, Average Loss: 0.0286\n",
            "Epoch 344, Average Loss: 0.0349\n",
            "Epoch 345, Average Loss: 0.0134\n",
            "Epoch 346, Average Loss: 0.0167\n",
            "Epoch 347, Average Loss: 0.0136\n",
            "Epoch 348, Average Loss: 0.0134\n",
            "Epoch 349, Average Loss: 0.0176\n",
            "Epoch 350, Average Loss: 0.0153\n",
            "Epoch 351, Average Loss: 0.0152\n",
            "Epoch 352, Average Loss: 0.0128\n",
            "Epoch 353, Average Loss: 0.0133\n",
            "Epoch 354, Average Loss: 0.0141\n",
            "Epoch 355, Average Loss: 0.0183\n",
            "Epoch 356, Average Loss: 0.0129\n",
            "Epoch 357, Average Loss: 0.0132\n",
            "Epoch 358, Average Loss: 0.0134\n",
            "Epoch 359, Average Loss: 0.0150\n",
            "Epoch 360, Average Loss: 0.0167\n",
            "Epoch 361, Average Loss: 0.0124\n",
            "Epoch 362, Average Loss: 0.0269\n",
            "Epoch 363, Average Loss: 0.0165\n",
            "Epoch 364, Average Loss: 0.0364\n",
            "Epoch 365, Average Loss: 0.0171\n",
            "Epoch 366, Average Loss: 0.0126\n",
            "Epoch 367, Average Loss: 0.0284\n",
            "Epoch 368, Average Loss: 0.0121\n",
            "Epoch 369, Average Loss: 0.0160\n",
            "Epoch 370, Average Loss: 0.0159\n",
            "Epoch 371, Average Loss: 0.0123\n",
            "Epoch 372, Average Loss: 0.0152\n",
            "Epoch 373, Average Loss: 0.0241\n",
            "Epoch 374, Average Loss: 0.0129\n",
            "Epoch 375, Average Loss: 0.0341\n",
            "Epoch 376, Average Loss: 0.0115\n",
            "Epoch 377, Average Loss: 0.0144\n",
            "Epoch 378, Average Loss: 0.0120\n",
            "Epoch 379, Average Loss: 0.0125\n",
            "Epoch 380, Average Loss: 0.0139\n",
            "Epoch 381, Average Loss: 0.0129\n",
            "Epoch 382, Average Loss: 0.0129\n",
            "Epoch 383, Average Loss: 0.0116\n",
            "Epoch 384, Average Loss: 0.0108\n",
            "Epoch 385, Average Loss: 0.0123\n",
            "Epoch 386, Average Loss: 0.0122\n",
            "Epoch 387, Average Loss: 0.0108\n",
            "Epoch 388, Average Loss: 0.0115\n",
            "Epoch 389, Average Loss: 0.0129\n",
            "Epoch 390, Average Loss: 0.0118\n",
            "Epoch 391, Average Loss: 0.0124\n",
            "Epoch 392, Average Loss: 0.0220\n",
            "Epoch 393, Average Loss: 0.0500\n",
            "Epoch 394, Average Loss: 0.0263\n",
            "Epoch 395, Average Loss: 0.0495\n",
            "Epoch 396, Average Loss: 0.0240\n",
            "Epoch 397, Average Loss: 0.0295\n",
            "Epoch 398, Average Loss: 0.0258\n",
            "Epoch 399, Average Loss: 0.0202\n",
            "Epoch 400, Average Loss: 0.0188\n",
            "Epoch 401, Average Loss: 0.0142\n",
            "Epoch 402, Average Loss: 0.0160\n",
            "Epoch 403, Average Loss: 0.0202\n",
            "Epoch 404, Average Loss: 0.0131\n",
            "Epoch 405, Average Loss: 0.0214\n",
            "Epoch 406, Average Loss: 0.0189\n",
            "Epoch 407, Average Loss: 0.0185\n",
            "Epoch 408, Average Loss: 0.0336\n",
            "Epoch 409, Average Loss: 0.0172\n",
            "Epoch 410, Average Loss: 0.0133\n",
            "Epoch 411, Average Loss: 0.0239\n",
            "Epoch 412, Average Loss: 0.0128\n",
            "Epoch 413, Average Loss: 0.0147\n",
            "Epoch 414, Average Loss: 0.0116\n",
            "Epoch 415, Average Loss: 0.0180\n",
            "Epoch 416, Average Loss: 0.0117\n",
            "Epoch 417, Average Loss: 0.0119\n",
            "Epoch 418, Average Loss: 0.0125\n",
            "Epoch 419, Average Loss: 0.0199\n",
            "Epoch 420, Average Loss: 0.0259\n",
            "Epoch 421, Average Loss: 0.0163\n",
            "Epoch 422, Average Loss: 0.0143\n",
            "Epoch 423, Average Loss: 0.0199\n",
            "Epoch 424, Average Loss: 0.0171\n",
            "Epoch 425, Average Loss: 0.0162\n",
            "Epoch 426, Average Loss: 0.0147\n",
            "Epoch 427, Average Loss: 0.0145\n",
            "Epoch 428, Average Loss: 0.0147\n",
            "Epoch 429, Average Loss: 0.0176\n",
            "Epoch 430, Average Loss: 0.0160\n",
            "Epoch 431, Average Loss: 0.0193\n",
            "Epoch 432, Average Loss: 0.0153\n",
            "Epoch 433, Average Loss: 0.0167\n",
            "Epoch 434, Average Loss: 0.0148\n",
            "Epoch 435, Average Loss: 0.0206\n",
            "Epoch 436, Average Loss: 0.0117\n",
            "Epoch 437, Average Loss: 0.0304\n",
            "Epoch 438, Average Loss: 0.0332\n",
            "Epoch 439, Average Loss: 0.0579\n",
            "Epoch 440, Average Loss: 0.0230\n",
            "Epoch 441, Average Loss: 0.0163\n",
            "Epoch 442, Average Loss: 0.0183\n",
            "Epoch 443, Average Loss: 0.0105\n",
            "Epoch 444, Average Loss: 0.0107\n",
            "Epoch 445, Average Loss: 0.0204\n",
            "Epoch 446, Average Loss: 0.0146\n",
            "Epoch 447, Average Loss: 0.0122\n",
            "Epoch 448, Average Loss: 0.0123\n",
            "Epoch 449, Average Loss: 0.0102\n",
            "Epoch 450, Average Loss: 0.0106\n",
            "Epoch 451, Average Loss: 0.0116\n",
            "Epoch 452, Average Loss: 0.0170\n",
            "Epoch 453, Average Loss: 0.0326\n",
            "Epoch 454, Average Loss: 0.0214\n",
            "Epoch 455, Average Loss: 0.0550\n",
            "Epoch 456, Average Loss: 0.0197\n",
            "Epoch 457, Average Loss: 0.0770\n",
            "Epoch 458, Average Loss: 0.0236\n",
            "Epoch 459, Average Loss: 0.0408\n",
            "Epoch 460, Average Loss: 0.0262\n",
            "Epoch 461, Average Loss: 0.0442\n",
            "Epoch 462, Average Loss: 0.0168\n",
            "Epoch 463, Average Loss: 0.0315\n",
            "Epoch 464, Average Loss: 0.0249\n",
            "Epoch 465, Average Loss: 0.0153\n",
            "Epoch 466, Average Loss: 0.0203\n",
            "Epoch 467, Average Loss: 0.0174\n",
            "Epoch 468, Average Loss: 0.0166\n",
            "Epoch 469, Average Loss: 0.0133\n",
            "Epoch 470, Average Loss: 0.0135\n",
            "Epoch 471, Average Loss: 0.0226\n",
            "Epoch 472, Average Loss: 0.0159\n",
            "Epoch 473, Average Loss: 0.0197\n",
            "Epoch 474, Average Loss: 0.0144\n",
            "Epoch 475, Average Loss: 0.0136\n",
            "Epoch 476, Average Loss: 0.0138\n",
            "Epoch 477, Average Loss: 0.0169\n",
            "Epoch 478, Average Loss: 0.0140\n",
            "Epoch 479, Average Loss: 0.0138\n",
            "Epoch 480, Average Loss: 0.0129\n",
            "Epoch 481, Average Loss: 0.0121\n",
            "Epoch 482, Average Loss: 0.0131\n",
            "Epoch 483, Average Loss: 0.0125\n",
            "Epoch 484, Average Loss: 0.0117\n",
            "Epoch 485, Average Loss: 0.0131\n",
            "Epoch 486, Average Loss: 0.0130\n",
            "Epoch 487, Average Loss: 0.0100\n",
            "Epoch 488, Average Loss: 0.0171\n",
            "Epoch 489, Average Loss: 0.0272\n",
            "Epoch 490, Average Loss: 0.0118\n",
            "Epoch 491, Average Loss: 0.0491\n",
            "Epoch 492, Average Loss: 0.0219\n",
            "Epoch 493, Average Loss: 0.0370\n",
            "Epoch 494, Average Loss: 0.0227\n",
            "Epoch 495, Average Loss: 0.0371\n",
            "Epoch 496, Average Loss: 0.0281\n",
            "Epoch 497, Average Loss: 0.0480\n",
            "Epoch 498, Average Loss: 0.0161\n",
            "Epoch 499, Average Loss: 0.0101\n",
            "Epoch 500, Average Loss: 0.0105\n",
            "Fold 4/5\n",
            "Node-level Accuracy: 0.9459, Graph-level Accuracy: 0.9333\n",
            "Epoch 1, Average Loss: 9.8228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Average Loss: 0.8455\n",
            "Epoch 3, Average Loss: 1.4574\n",
            "Epoch 4, Average Loss: 1.1216\n",
            "Epoch 5, Average Loss: 0.3808\n",
            "Epoch 6, Average Loss: 0.4602\n",
            "Epoch 7, Average Loss: 0.5846\n",
            "Epoch 8, Average Loss: 0.4577\n",
            "Epoch 9, Average Loss: 0.4591\n",
            "Epoch 10, Average Loss: 0.6223\n",
            "Epoch 11, Average Loss: 0.8564\n",
            "Epoch 12, Average Loss: 1.5157\n",
            "Epoch 13, Average Loss: 0.3930\n",
            "Epoch 14, Average Loss: 0.8085\n",
            "Epoch 15, Average Loss: 0.6490\n",
            "Epoch 16, Average Loss: 0.3828\n",
            "Epoch 17, Average Loss: 0.3883\n",
            "Epoch 18, Average Loss: 0.3465\n",
            "Epoch 19, Average Loss: 0.4213\n",
            "Epoch 20, Average Loss: 0.3742\n",
            "Epoch 21, Average Loss: 0.3466\n",
            "Epoch 22, Average Loss: 0.3325\n",
            "Epoch 23, Average Loss: 0.3299\n",
            "Epoch 24, Average Loss: 0.3390\n",
            "Epoch 25, Average Loss: 0.3397\n",
            "Epoch 26, Average Loss: 0.3099\n",
            "Epoch 27, Average Loss: 0.3016\n",
            "Epoch 28, Average Loss: 0.3437\n",
            "Epoch 29, Average Loss: 0.3035\n",
            "Epoch 30, Average Loss: 0.3097\n",
            "Epoch 31, Average Loss: 0.2975\n",
            "Epoch 32, Average Loss: 0.3006\n",
            "Epoch 33, Average Loss: 0.2833\n",
            "Epoch 34, Average Loss: 0.2906\n",
            "Epoch 35, Average Loss: 0.3001\n",
            "Epoch 36, Average Loss: 0.3318\n",
            "Epoch 37, Average Loss: 0.2980\n",
            "Epoch 38, Average Loss: 0.3073\n",
            "Epoch 39, Average Loss: 0.2794\n",
            "Epoch 40, Average Loss: 0.3217\n",
            "Epoch 41, Average Loss: 0.3163\n",
            "Epoch 42, Average Loss: 0.3094\n",
            "Epoch 43, Average Loss: 0.2846\n",
            "Epoch 44, Average Loss: 0.2739\n",
            "Epoch 45, Average Loss: 0.2932\n",
            "Epoch 46, Average Loss: 0.3060\n",
            "Epoch 47, Average Loss: 0.2818\n",
            "Epoch 48, Average Loss: 0.3092\n",
            "Epoch 49, Average Loss: 0.2841\n",
            "Epoch 50, Average Loss: 0.2734\n",
            "Epoch 51, Average Loss: 0.2967\n",
            "Epoch 52, Average Loss: 0.3102\n",
            "Epoch 53, Average Loss: 0.2888\n",
            "Epoch 54, Average Loss: 0.3155\n",
            "Epoch 55, Average Loss: 0.2708\n",
            "Epoch 56, Average Loss: 0.2811\n",
            "Epoch 57, Average Loss: 0.2910\n",
            "Epoch 58, Average Loss: 0.3047\n",
            "Epoch 59, Average Loss: 0.2757\n",
            "Epoch 60, Average Loss: 0.2744\n",
            "Epoch 61, Average Loss: 0.2855\n",
            "Epoch 62, Average Loss: 0.2898\n",
            "Epoch 63, Average Loss: 0.2739\n",
            "Epoch 64, Average Loss: 0.2804\n",
            "Epoch 65, Average Loss: 0.2744\n",
            "Epoch 66, Average Loss: 0.2708\n",
            "Epoch 67, Average Loss: 0.2744\n",
            "Epoch 68, Average Loss: 0.2672\n",
            "Epoch 69, Average Loss: 0.2779\n",
            "Epoch 70, Average Loss: 0.2845\n",
            "Epoch 71, Average Loss: 0.2709\n",
            "Epoch 72, Average Loss: 0.2869\n",
            "Epoch 73, Average Loss: 0.2918\n",
            "Epoch 74, Average Loss: 0.2938\n",
            "Epoch 75, Average Loss: 0.2689\n",
            "Epoch 76, Average Loss: 0.3001\n",
            "Epoch 77, Average Loss: 0.2743\n",
            "Epoch 78, Average Loss: 0.2603\n",
            "Epoch 79, Average Loss: 0.2655\n",
            "Epoch 80, Average Loss: 0.2676\n",
            "Epoch 81, Average Loss: 0.2638\n",
            "Epoch 82, Average Loss: 0.2612\n",
            "Epoch 83, Average Loss: 0.2518\n",
            "Epoch 84, Average Loss: 0.3189\n",
            "Epoch 85, Average Loss: 0.2703\n",
            "Epoch 86, Average Loss: 0.2554\n",
            "Epoch 87, Average Loss: 0.2731\n",
            "Epoch 88, Average Loss: 0.2642\n",
            "Epoch 89, Average Loss: 0.2600\n",
            "Epoch 90, Average Loss: 0.2658\n",
            "Epoch 91, Average Loss: 0.2642\n",
            "Epoch 92, Average Loss: 0.2935\n",
            "Epoch 93, Average Loss: 0.2671\n",
            "Epoch 94, Average Loss: 0.2659\n",
            "Epoch 95, Average Loss: 0.2510\n",
            "Epoch 96, Average Loss: 0.2610\n",
            "Epoch 97, Average Loss: 0.2687\n",
            "Epoch 98, Average Loss: 0.2631\n",
            "Epoch 99, Average Loss: 0.2616\n",
            "Epoch 100, Average Loss: 0.2922\n",
            "Epoch 101, Average Loss: 0.2632\n",
            "Epoch 102, Average Loss: 0.2823\n",
            "Epoch 103, Average Loss: 0.2710\n",
            "Epoch 104, Average Loss: 0.2695\n",
            "Epoch 105, Average Loss: 0.3009\n",
            "Epoch 106, Average Loss: 0.2647\n",
            "Epoch 107, Average Loss: 0.2604\n",
            "Epoch 108, Average Loss: 0.2801\n",
            "Epoch 109, Average Loss: 0.2584\n",
            "Epoch 110, Average Loss: 0.2583\n",
            "Epoch 111, Average Loss: 0.2574\n",
            "Epoch 112, Average Loss: 0.2768\n",
            "Epoch 113, Average Loss: 0.2514\n",
            "Epoch 114, Average Loss: 0.2579\n",
            "Epoch 115, Average Loss: 0.2826\n",
            "Epoch 116, Average Loss: 0.2773\n",
            "Epoch 117, Average Loss: 0.2547\n",
            "Epoch 118, Average Loss: 0.2776\n",
            "Epoch 119, Average Loss: 0.2689\n",
            "Epoch 120, Average Loss: 0.2685\n",
            "Epoch 121, Average Loss: 0.2816\n",
            "Epoch 122, Average Loss: 0.2757\n",
            "Epoch 123, Average Loss: 0.2521\n",
            "Epoch 124, Average Loss: 0.2719\n",
            "Epoch 125, Average Loss: 0.2842\n",
            "Epoch 126, Average Loss: 0.2551\n",
            "Epoch 127, Average Loss: 0.2650\n",
            "Epoch 128, Average Loss: 0.2626\n",
            "Epoch 129, Average Loss: 0.2505\n",
            "Epoch 130, Average Loss: 0.2659\n",
            "Epoch 131, Average Loss: 0.2595\n",
            "Epoch 132, Average Loss: 0.2499\n",
            "Epoch 133, Average Loss: 0.2594\n",
            "Epoch 134, Average Loss: 0.2681\n",
            "Epoch 135, Average Loss: 0.2719\n",
            "Epoch 136, Average Loss: 0.2663\n",
            "Epoch 137, Average Loss: 0.2573\n",
            "Epoch 138, Average Loss: 0.2608\n",
            "Epoch 139, Average Loss: 0.2442\n",
            "Epoch 140, Average Loss: 0.2517\n",
            "Epoch 141, Average Loss: 0.2511\n",
            "Epoch 142, Average Loss: 0.2669\n",
            "Epoch 143, Average Loss: 0.2564\n",
            "Epoch 144, Average Loss: 0.2524\n",
            "Epoch 145, Average Loss: 0.2806\n",
            "Epoch 146, Average Loss: 0.2689\n",
            "Epoch 147, Average Loss: 0.2503\n",
            "Epoch 148, Average Loss: 0.2488\n",
            "Epoch 149, Average Loss: 0.2499\n",
            "Epoch 150, Average Loss: 0.2712\n",
            "Epoch 151, Average Loss: 0.2585\n",
            "Epoch 152, Average Loss: 0.2425\n",
            "Epoch 153, Average Loss: 0.2445\n",
            "Epoch 154, Average Loss: 0.2514\n",
            "Epoch 155, Average Loss: 0.2453\n",
            "Epoch 156, Average Loss: 0.2484\n",
            "Epoch 157, Average Loss: 0.2493\n",
            "Epoch 158, Average Loss: 0.2517\n",
            "Epoch 159, Average Loss: 0.2555\n",
            "Epoch 160, Average Loss: 0.2538\n",
            "Epoch 161, Average Loss: 0.2411\n",
            "Epoch 162, Average Loss: 0.2393\n",
            "Epoch 163, Average Loss: 0.2717\n",
            "Epoch 164, Average Loss: 0.2806\n",
            "Epoch 165, Average Loss: 0.2395\n",
            "Epoch 166, Average Loss: 0.2707\n",
            "Epoch 167, Average Loss: 0.2500\n",
            "Epoch 168, Average Loss: 0.2595\n",
            "Epoch 169, Average Loss: 0.2676\n",
            "Epoch 170, Average Loss: 0.2716\n",
            "Epoch 171, Average Loss: 0.2456\n",
            "Epoch 172, Average Loss: 0.2888\n",
            "Epoch 173, Average Loss: 0.2369\n",
            "Epoch 174, Average Loss: 0.2554\n",
            "Epoch 175, Average Loss: 0.2438\n",
            "Epoch 176, Average Loss: 0.2590\n",
            "Epoch 177, Average Loss: 0.2513\n",
            "Epoch 178, Average Loss: 0.2386\n",
            "Epoch 179, Average Loss: 0.2497\n",
            "Epoch 180, Average Loss: 0.2422\n",
            "Epoch 181, Average Loss: 0.2377\n",
            "Epoch 182, Average Loss: 0.2350\n",
            "Epoch 183, Average Loss: 0.2574\n",
            "Epoch 184, Average Loss: 0.2518\n",
            "Epoch 185, Average Loss: 0.2327\n",
            "Epoch 186, Average Loss: 0.2346\n",
            "Epoch 187, Average Loss: 0.2414\n",
            "Epoch 188, Average Loss: 0.2304\n",
            "Epoch 189, Average Loss: 0.2461\n",
            "Epoch 190, Average Loss: 0.2415\n",
            "Epoch 191, Average Loss: 0.2447\n",
            "Epoch 192, Average Loss: 0.2295\n",
            "Epoch 193, Average Loss: 0.2369\n",
            "Epoch 194, Average Loss: 0.2491\n",
            "Epoch 195, Average Loss: 0.2345\n",
            "Epoch 196, Average Loss: 0.2402\n",
            "Epoch 197, Average Loss: 0.2341\n",
            "Epoch 198, Average Loss: 0.2366\n",
            "Epoch 199, Average Loss: 0.2375\n",
            "Epoch 200, Average Loss: 0.2337\n",
            "Epoch 201, Average Loss: 0.2292\n",
            "Epoch 202, Average Loss: 0.2497\n",
            "Epoch 203, Average Loss: 0.2235\n",
            "Epoch 204, Average Loss: 0.2302\n",
            "Epoch 205, Average Loss: 0.2325\n",
            "Epoch 206, Average Loss: 0.2266\n",
            "Epoch 207, Average Loss: 0.2505\n",
            "Epoch 208, Average Loss: 0.2180\n",
            "Epoch 209, Average Loss: 0.2407\n",
            "Epoch 210, Average Loss: 0.2253\n",
            "Epoch 211, Average Loss: 0.2261\n",
            "Epoch 212, Average Loss: 0.2337\n",
            "Epoch 213, Average Loss: 0.2176\n",
            "Epoch 214, Average Loss: 0.2236\n",
            "Epoch 215, Average Loss: 0.2483\n",
            "Epoch 216, Average Loss: 0.2274\n",
            "Epoch 217, Average Loss: 0.2232\n",
            "Epoch 218, Average Loss: 0.2142\n",
            "Epoch 219, Average Loss: 0.2522\n",
            "Epoch 220, Average Loss: 0.2231\n",
            "Epoch 221, Average Loss: 0.2215\n",
            "Epoch 222, Average Loss: 0.2130\n",
            "Epoch 223, Average Loss: 0.2203\n",
            "Epoch 224, Average Loss: 0.2466\n",
            "Epoch 225, Average Loss: 0.2191\n",
            "Epoch 226, Average Loss: 0.2145\n",
            "Epoch 227, Average Loss: 0.2266\n",
            "Epoch 228, Average Loss: 0.2416\n",
            "Epoch 229, Average Loss: 0.2225\n",
            "Epoch 230, Average Loss: 0.2255\n",
            "Epoch 231, Average Loss: 0.2425\n",
            "Epoch 232, Average Loss: 0.2227\n",
            "Epoch 233, Average Loss: 0.2465\n",
            "Epoch 234, Average Loss: 0.2145\n",
            "Epoch 235, Average Loss: 0.2371\n",
            "Epoch 236, Average Loss: 0.2287\n",
            "Epoch 237, Average Loss: 0.2165\n",
            "Epoch 238, Average Loss: 0.2305\n",
            "Epoch 239, Average Loss: 0.2154\n",
            "Epoch 240, Average Loss: 0.2256\n",
            "Epoch 241, Average Loss: 0.2224\n",
            "Epoch 242, Average Loss: 0.2368\n",
            "Epoch 243, Average Loss: 0.2208\n",
            "Epoch 244, Average Loss: 0.2481\n",
            "Epoch 245, Average Loss: 0.2407\n",
            "Epoch 246, Average Loss: 0.2190\n",
            "Epoch 247, Average Loss: 0.2153\n",
            "Epoch 248, Average Loss: 0.2173\n",
            "Epoch 249, Average Loss: 0.2160\n",
            "Epoch 250, Average Loss: 0.2309\n",
            "Epoch 251, Average Loss: 0.2258\n",
            "Epoch 252, Average Loss: 0.2190\n",
            "Epoch 253, Average Loss: 0.2130\n",
            "Epoch 254, Average Loss: 0.2143\n",
            "Epoch 255, Average Loss: 0.2475\n",
            "Epoch 256, Average Loss: 0.2227\n",
            "Epoch 257, Average Loss: 0.2193\n",
            "Epoch 258, Average Loss: 0.2160\n",
            "Epoch 259, Average Loss: 0.2379\n",
            "Epoch 260, Average Loss: 0.2227\n",
            "Epoch 261, Average Loss: 0.2254\n",
            "Epoch 262, Average Loss: 0.2110\n",
            "Epoch 263, Average Loss: 0.2481\n",
            "Epoch 264, Average Loss: 0.2097\n",
            "Epoch 265, Average Loss: 0.2182\n",
            "Epoch 266, Average Loss: 0.2149\n",
            "Epoch 267, Average Loss: 0.2155\n",
            "Epoch 268, Average Loss: 0.2167\n",
            "Epoch 269, Average Loss: 0.2121\n",
            "Epoch 270, Average Loss: 0.2171\n",
            "Epoch 271, Average Loss: 0.2206\n",
            "Epoch 272, Average Loss: 0.2200\n",
            "Epoch 273, Average Loss: 0.2136\n",
            "Epoch 274, Average Loss: 0.2093\n",
            "Epoch 275, Average Loss: 0.2203\n",
            "Epoch 276, Average Loss: 0.2372\n",
            "Epoch 277, Average Loss: 0.2209\n",
            "Epoch 278, Average Loss: 0.2236\n",
            "Epoch 279, Average Loss: 0.2057\n",
            "Epoch 280, Average Loss: 0.2136\n",
            "Epoch 281, Average Loss: 0.2148\n",
            "Epoch 282, Average Loss: 0.2213\n",
            "Epoch 283, Average Loss: 0.2098\n",
            "Epoch 284, Average Loss: 0.2395\n",
            "Epoch 285, Average Loss: 0.2201\n",
            "Epoch 286, Average Loss: 0.2241\n",
            "Epoch 287, Average Loss: 0.2154\n",
            "Epoch 288, Average Loss: 0.2184\n",
            "Epoch 289, Average Loss: 0.2220\n",
            "Epoch 290, Average Loss: 0.2094\n",
            "Epoch 291, Average Loss: 0.2160\n",
            "Epoch 292, Average Loss: 0.2143\n",
            "Epoch 293, Average Loss: 0.2319\n",
            "Epoch 294, Average Loss: 0.2184\n",
            "Epoch 295, Average Loss: 0.2203\n",
            "Epoch 296, Average Loss: 0.2311\n",
            "Epoch 297, Average Loss: 0.2360\n",
            "Epoch 298, Average Loss: 0.2151\n",
            "Epoch 299, Average Loss: 0.2189\n",
            "Epoch 300, Average Loss: 0.2296\n",
            "Epoch 301, Average Loss: 0.2137\n",
            "Epoch 302, Average Loss: 0.2141\n",
            "Epoch 303, Average Loss: 0.2097\n",
            "Epoch 304, Average Loss: 0.2301\n",
            "Epoch 305, Average Loss: 0.2240\n",
            "Epoch 306, Average Loss: 0.2264\n",
            "Epoch 307, Average Loss: 0.2368\n",
            "Epoch 308, Average Loss: 0.2271\n",
            "Epoch 309, Average Loss: 0.2435\n",
            "Epoch 310, Average Loss: 0.2177\n",
            "Epoch 311, Average Loss: 0.2167\n",
            "Epoch 312, Average Loss: 0.2352\n",
            "Epoch 313, Average Loss: 0.2150\n",
            "Epoch 314, Average Loss: 0.2296\n",
            "Epoch 315, Average Loss: 0.2152\n",
            "Epoch 316, Average Loss: 0.2095\n",
            "Epoch 317, Average Loss: 0.2418\n",
            "Epoch 318, Average Loss: 0.2146\n",
            "Epoch 319, Average Loss: 0.2071\n",
            "Epoch 320, Average Loss: 0.2313\n",
            "Epoch 321, Average Loss: 0.2111\n",
            "Epoch 322, Average Loss: 0.2047\n",
            "Epoch 323, Average Loss: 0.2039\n",
            "Epoch 324, Average Loss: 0.2035\n",
            "Epoch 325, Average Loss: 0.2043\n",
            "Epoch 326, Average Loss: 0.2047\n",
            "Epoch 327, Average Loss: 0.2210\n",
            "Epoch 328, Average Loss: 0.2130\n",
            "Epoch 329, Average Loss: 0.2173\n",
            "Epoch 330, Average Loss: 0.2048\n",
            "Epoch 331, Average Loss: 0.2042\n",
            "Epoch 332, Average Loss: 0.2165\n",
            "Epoch 333, Average Loss: 0.2095\n",
            "Epoch 334, Average Loss: 0.2095\n",
            "Epoch 335, Average Loss: 0.2094\n",
            "Epoch 336, Average Loss: 0.2072\n",
            "Epoch 337, Average Loss: 0.2039\n",
            "Epoch 338, Average Loss: 0.2063\n",
            "Epoch 339, Average Loss: 0.2138\n",
            "Epoch 340, Average Loss: 0.2200\n",
            "Epoch 341, Average Loss: 0.2196\n",
            "Epoch 342, Average Loss: 0.2130\n",
            "Epoch 343, Average Loss: 0.2280\n",
            "Epoch 344, Average Loss: 0.2092\n",
            "Epoch 345, Average Loss: 0.2224\n",
            "Epoch 346, Average Loss: 0.2217\n",
            "Epoch 347, Average Loss: 0.2189\n",
            "Epoch 348, Average Loss: 0.2119\n",
            "Epoch 349, Average Loss: 0.2054\n",
            "Epoch 350, Average Loss: 0.2105\n",
            "Epoch 351, Average Loss: 0.2135\n",
            "Epoch 352, Average Loss: 0.2112\n",
            "Epoch 353, Average Loss: 0.2066\n",
            "Epoch 354, Average Loss: 0.2150\n",
            "Epoch 355, Average Loss: 0.2090\n",
            "Epoch 356, Average Loss: 0.2129\n",
            "Epoch 357, Average Loss: 0.2311\n",
            "Epoch 358, Average Loss: 0.2155\n",
            "Epoch 359, Average Loss: 0.2140\n",
            "Epoch 360, Average Loss: 0.2122\n",
            "Epoch 361, Average Loss: 0.2077\n",
            "Epoch 362, Average Loss: 0.2238\n",
            "Epoch 363, Average Loss: 0.2114\n",
            "Epoch 364, Average Loss: 0.2082\n",
            "Epoch 365, Average Loss: 0.2285\n",
            "Epoch 366, Average Loss: 0.2363\n",
            "Epoch 367, Average Loss: 0.2121\n",
            "Epoch 368, Average Loss: 0.2261\n",
            "Epoch 369, Average Loss: 0.2087\n",
            "Epoch 370, Average Loss: 0.2048\n",
            "Epoch 371, Average Loss: 0.2029\n",
            "Epoch 372, Average Loss: 0.2232\n",
            "Epoch 373, Average Loss: 0.2142\n",
            "Epoch 374, Average Loss: 0.2225\n",
            "Epoch 375, Average Loss: 0.2204\n",
            "Epoch 376, Average Loss: 0.2094\n",
            "Epoch 377, Average Loss: 0.2127\n",
            "Epoch 378, Average Loss: 0.2055\n",
            "Epoch 379, Average Loss: 0.2248\n",
            "Epoch 380, Average Loss: 0.2219\n",
            "Epoch 381, Average Loss: 0.2007\n",
            "Epoch 382, Average Loss: 0.2265\n",
            "Epoch 383, Average Loss: 0.2077\n",
            "Epoch 384, Average Loss: 0.2080\n",
            "Epoch 385, Average Loss: 0.2106\n",
            "Epoch 386, Average Loss: 0.2059\n",
            "Epoch 387, Average Loss: 0.2117\n",
            "Epoch 388, Average Loss: 0.2090\n",
            "Epoch 389, Average Loss: 0.2050\n",
            "Epoch 390, Average Loss: 0.2033\n",
            "Epoch 391, Average Loss: 0.2010\n",
            "Epoch 392, Average Loss: 0.2071\n",
            "Epoch 393, Average Loss: 0.2127\n",
            "Epoch 394, Average Loss: 0.2033\n",
            "Epoch 395, Average Loss: 0.2174\n",
            "Epoch 396, Average Loss: 0.2136\n",
            "Epoch 397, Average Loss: 0.2331\n",
            "Epoch 398, Average Loss: 0.2275\n",
            "Epoch 399, Average Loss: 0.2102\n",
            "Epoch 400, Average Loss: 0.2119\n",
            "Epoch 401, Average Loss: 0.2220\n",
            "Epoch 402, Average Loss: 0.2172\n",
            "Epoch 403, Average Loss: 0.2095\n",
            "Epoch 404, Average Loss: 0.2172\n",
            "Epoch 405, Average Loss: 0.1966\n",
            "Epoch 406, Average Loss: 0.2042\n",
            "Epoch 407, Average Loss: 0.2116\n",
            "Epoch 408, Average Loss: 0.2050\n",
            "Epoch 409, Average Loss: 0.1981\n",
            "Epoch 410, Average Loss: 0.2283\n",
            "Epoch 411, Average Loss: 0.1969\n",
            "Epoch 412, Average Loss: 0.2088\n",
            "Epoch 413, Average Loss: 0.2006\n",
            "Epoch 414, Average Loss: 0.2019\n",
            "Epoch 415, Average Loss: 0.2128\n",
            "Epoch 416, Average Loss: 0.2102\n",
            "Epoch 417, Average Loss: 0.2110\n",
            "Epoch 418, Average Loss: 0.1833\n",
            "Epoch 419, Average Loss: 0.1972\n",
            "Epoch 420, Average Loss: 0.1947\n",
            "Epoch 421, Average Loss: 0.2075\n",
            "Epoch 422, Average Loss: 0.1895\n",
            "Epoch 423, Average Loss: 0.1912\n",
            "Epoch 424, Average Loss: 0.1853\n",
            "Epoch 425, Average Loss: 0.1820\n",
            "Epoch 426, Average Loss: 0.1725\n",
            "Epoch 427, Average Loss: 0.1929\n",
            "Epoch 428, Average Loss: 0.1827\n",
            "Epoch 429, Average Loss: 0.1838\n",
            "Epoch 430, Average Loss: 0.1915\n",
            "Epoch 431, Average Loss: 0.1827\n",
            "Epoch 432, Average Loss: 0.1751\n",
            "Epoch 433, Average Loss: 0.1828\n",
            "Epoch 434, Average Loss: 0.1832\n",
            "Epoch 435, Average Loss: 0.1753\n",
            "Epoch 436, Average Loss: 0.1798\n",
            "Epoch 437, Average Loss: 0.1847\n",
            "Epoch 438, Average Loss: 0.1740\n",
            "Epoch 439, Average Loss: 0.2012\n",
            "Epoch 440, Average Loss: 0.1816\n",
            "Epoch 441, Average Loss: 0.1860\n",
            "Epoch 442, Average Loss: 0.1883\n",
            "Epoch 443, Average Loss: 0.1828\n",
            "Epoch 444, Average Loss: 0.1836\n",
            "Epoch 445, Average Loss: 0.1876\n",
            "Epoch 446, Average Loss: 0.1917\n",
            "Epoch 447, Average Loss: 0.1793\n",
            "Epoch 448, Average Loss: 0.1729\n",
            "Epoch 449, Average Loss: 0.1833\n",
            "Epoch 450, Average Loss: 0.1754\n",
            "Epoch 451, Average Loss: 0.1822\n",
            "Epoch 452, Average Loss: 0.1813\n",
            "Epoch 453, Average Loss: 0.1897\n",
            "Epoch 454, Average Loss: 0.1792\n",
            "Epoch 455, Average Loss: 0.1848\n",
            "Epoch 456, Average Loss: 0.1848\n",
            "Epoch 457, Average Loss: 0.1805\n",
            "Epoch 458, Average Loss: 0.1795\n",
            "Epoch 459, Average Loss: 0.1843\n",
            "Epoch 460, Average Loss: 0.1940\n",
            "Epoch 461, Average Loss: 0.1796\n",
            "Epoch 462, Average Loss: 0.2038\n",
            "Epoch 463, Average Loss: 0.1994\n",
            "Epoch 464, Average Loss: 0.1801\n",
            "Epoch 465, Average Loss: 0.1791\n",
            "Epoch 466, Average Loss: 0.1792\n",
            "Epoch 467, Average Loss: 0.1802\n",
            "Epoch 468, Average Loss: 0.1791\n",
            "Epoch 469, Average Loss: 0.1784\n",
            "Epoch 470, Average Loss: 0.1739\n",
            "Epoch 471, Average Loss: 0.1717\n",
            "Epoch 472, Average Loss: 0.1805\n",
            "Epoch 473, Average Loss: 0.1777\n",
            "Epoch 474, Average Loss: 0.1825\n",
            "Epoch 475, Average Loss: 0.1759\n",
            "Epoch 476, Average Loss: 0.1709\n",
            "Epoch 477, Average Loss: 0.2011\n",
            "Epoch 478, Average Loss: 0.1811\n",
            "Epoch 479, Average Loss: 0.1735\n",
            "Epoch 480, Average Loss: 0.1789\n",
            "Epoch 481, Average Loss: 0.1755\n",
            "Epoch 482, Average Loss: 0.1912\n",
            "Epoch 483, Average Loss: 0.1807\n",
            "Epoch 484, Average Loss: 0.1800\n",
            "Epoch 485, Average Loss: 0.1796\n",
            "Epoch 486, Average Loss: 0.1767\n",
            "Epoch 487, Average Loss: 0.2044\n",
            "Epoch 488, Average Loss: 0.1809\n",
            "Epoch 489, Average Loss: 0.1984\n",
            "Epoch 490, Average Loss: 0.1686\n",
            "Epoch 491, Average Loss: 0.1736\n",
            "Epoch 492, Average Loss: 0.1921\n",
            "Epoch 493, Average Loss: 0.1714\n",
            "Epoch 494, Average Loss: 0.1727\n",
            "Epoch 495, Average Loss: 0.1735\n",
            "Epoch 496, Average Loss: 0.1715\n",
            "Epoch 497, Average Loss: 0.1823\n",
            "Epoch 498, Average Loss: 0.1906\n",
            "Epoch 499, Average Loss: 0.1716\n",
            "Epoch 500, Average Loss: 0.1745\n",
            "Fold 5/5\n",
            "Node-level Accuracy: 0.9756, Graph-level Accuracy: 1.0000\n",
            "Average Node-level Accuracy: 0.9542\n",
            "Average Graph-level Accuracy: 0.9200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ]
}